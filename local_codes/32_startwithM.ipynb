{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7cd1b0e-e0e4-4fd8-a680-ccdf0e1918a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "../checkpoints/Guess_M_checkpoints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gs11hgdu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>lr</td><td>██▁</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>val_accuracy</td><td>▁█▆</td></tr><tr><td>val_f1_macro</td><td>▁█▆</td></tr><tr><td>val_f1_micro</td><td>▁█▆</td></tr><tr><td>val_loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.25196</td></tr><tr><td>val_accuracy</td><td>0.86094</td></tr><tr><td>val_f1_macro</td><td>0.57485</td></tr><tr><td>val_f1_micro</td><td>0.86094</td></tr><tr><td>val_loss</td><td>0.29141</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-snowflake-4</strong> at: <a href='https://wandb.ai/alireza_noroozi/Guess_M/runs/gs11hgdu' target=\"_blank\">https://wandb.ai/alireza_noroozi/Guess_M/runs/gs11hgdu</a><br/> View project at: <a href='https://wandb.ai/alireza_noroozi/Guess_M' target=\"_blank\">https://wandb.ai/alireza_noroozi/Guess_M</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250102_180616-gs11hgdu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gs11hgdu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aac/Alireza/local_codes/wandb/run-20250102_181125-qblonuau</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alireza_noroozi/Guess_M/runs/qblonuau' target=\"_blank\">cool-serenity-5</a></strong> to <a href='https://wandb.ai/alireza_noroozi/Guess_M' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alireza_noroozi/Guess_M' target=\"_blank\">https://wandb.ai/alireza_noroozi/Guess_M</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alireza_noroozi/Guess_M/runs/qblonuau' target=\"_blank\">https://wandb.ai/alireza_noroozi/Guess_M/runs/qblonuau</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alireza_noroozi/Guess_M/runs/qblonuau?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x71e4d8169750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys, os, math\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "import json\n",
    "from transformers import EsmModel, AutoTokenizer, AutoModel\n",
    "\n",
    "sys.path.insert(0, '../dlp')\n",
    "from batch import Batch\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "epochs = 100_000\n",
    "val_epoch = 100\n",
    "num_val = 10\n",
    "batch_size = 64\n",
    "dataset_name = \"corpus_1000_Viruses_cellular\"\n",
    "lr = 0.001\n",
    "model_name = \"Guess_M\"\n",
    "max_seq_len = 1000\n",
    "\n",
    "from data_access import PQDataAccess\n",
    "da = PQDataAccess(f\"/home/aac/Alireza/datasets/export_pqt_4_taxseq_new/{dataset_name}\", batch_size)\n",
    "\n",
    "checkpoint_dir = f\"../checkpoints/{model_name}_checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "print(checkpoint_dir)\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=model_name,\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": model_name,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_szie\": batch_size,\n",
    "        \"max_seq_len\": max_seq_len\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2cb1410-5ec8-4c88-854d-be599e54e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM1b(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.esm = EsmModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "        \n",
    "        for param in self.esm.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Linear(1280, 512)\n",
    "        self.layer_norm = nn.LayerNorm(512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.layer2 = nn.Linear(512, 2)\n",
    "\n",
    "    def attention_pooling(self, x):\n",
    "        # x shape: (batch_size, seq_length, embedding_dim)\n",
    "        attention_weights = self.attention(x)  # (batch_size, seq_length, 1)\n",
    "        attention_weights = torch.softmax(attention_weights.squeeze(-1), dim=1)  # (batch_size, seq_length)\n",
    "        attention_weights = attention_weights.unsqueeze(-1)  # (batch_size, seq_length, 1)\n",
    "        pooled = torch.sum(x * attention_weights, dim=1)  # (batch_size, embedding_dim)\n",
    "        return pooled\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        outputs = self.esm(x, attention_mask=attention_mask).last_hidden_state\n",
    "        outputs = self.attention_pooling(outputs)\n",
    "        \n",
    "        outputs = self.layer1(outputs)\n",
    "        outputs = self.layer_norm(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.layer2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37fede89-9b77-4f1e-951b-3f6a2600d5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 0.986115 M\n",
      "Total parameters: 653.340056 M\n"
     ]
    }
   ],
   "source": [
    "model = ESM1b().to(device)\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f'Trainable parameters: {trainable/ 1e6} M')\n",
    "print(f'Total parameters: {total/ 1e6} M')\n",
    "# print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Cosine annealing with warm restarts\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=10,  # Period of learning rate decay\n",
    "    gamma=0.1  # Multiplicative factor of decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d31e550-ed8f-41a5-942f-90d86c3afe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ = AutoTokenizer.from_pretrained(f\"facebook/esm1b_t33_650M_UR50S\")\n",
    "\n",
    "def data_to_tensor_batch(b, max_seq_len=max_seq_len):\n",
    "    inputs = tokenizer_(\n",
    "        [e['Sequence'] for e in b],\n",
    "        return_tensors=\"pt\", \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        max_length=max_seq_len\n",
    "    )\n",
    "\n",
    "    labels = torch.LongTensor([\n",
    "        1 if e['Sequence'].startswith('M') else 0 for e in b\n",
    "    ])\n",
    "    \n",
    "    return Batch(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb03ada3-72a3-4e55-a292-7773574ce08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = [da.get_batch() for _ in range(num_val)]\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_val):\n",
    "        with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "            tensor_batch = data_to_tensor_batch(val_batches[epoch], max_seq_len)\n",
    "            tensor_batch.gpu(device)\n",
    "            labels = tensor_batch.taxes\n",
    "            \n",
    "        outputs = model(tensor_batch.seq_ids['input_ids'], tensor_batch.seq_ids['attention_mask'])\n",
    "        loss = criterion(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(all_labels.numpy(), all_preds.numpy())\n",
    "    f1_macro = f1_score(all_labels.numpy(), all_preds.numpy(), average='macro')\n",
    "    f1_micro = f1_score(all_labels.numpy(), all_preds.numpy(), average='micro')\n",
    "    conf_matrix = confusion_matrix(all_labels.numpy(), all_preds.numpy())\n",
    "    avg_loss = running_loss / num_val\n",
    "\n",
    "    return avg_loss, accuracy, f1_micro, f1_macro, conf_matrix\n",
    "\n",
    "\n",
    "# evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba451553-07c8-4608-821a-28078d720548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "def load_checkpoint(model, optimizer=None, scheduler=None):\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pt'))        \n",
    "    # Extract epoch numbers and find latest\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "    \n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Load optimizer state if provided (for training)\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        # Move optimizer state to GPU if necessary\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(device)\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Get training metadata\n",
    "    epoch = checkpoint['epoch']\n",
    "    metrics = checkpoint['metrics']\n",
    "    \n",
    "    print(f\"Successfully loaded checkpoint from epoch {epoch}\")\n",
    "    # print(\"Metrics at checkpoint:\", metrics)\n",
    "    \n",
    "    return model, optimizer, scheduler, epoch, metrics\n",
    "        \n",
    "\n",
    "# model, optimizer, scheduler, latest_epoch, metrics = load_checkpoint(model, optimizer, scheduler)\n",
    "latest_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b487e-69ce-4c41-be78-a1b6dcb58e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/100000 [07:30<126:36:26,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100000]\n",
      "Train Loss: 0.2389\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 199/100000 [15:58<126:09:14,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/100000]\n",
      "Train Loss: 0.1061\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 299/100000 [24:24<126:01:39,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/100000]\n",
      "Train Loss: 0.0798\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 399/100000 [32:52<125:51:07,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/100000]\n",
      "Train Loss: 0.0496\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 499/100000 [41:19<126:18:55,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/100000]\n",
      "Train Loss: 0.0775\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  1%|          | 599/100000 [49:45<125:47:32,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [600/100000]\n",
      "Train Loss: 0.1134\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  1%|          | 699/100000 [58:12<125:29:01,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [700/100000]\n",
      "Train Loss: 0.0635\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  1%|          | 799/100000 [1:06:39<125:34:47,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [800/100000]\n",
      "Train Loss: 0.0588\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  2%|▏         | 1899/100000 [2:39:40<124:13:42,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1900/100000]\n",
      "Train Loss: 0.2148\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  2%|▏         | 1999/100000 [2:48:07<124:03:02,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/100000]\n",
      "Train Loss: 0.2671\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  2%|▏         | 2099/100000 [2:56:35<124:26:31,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2100/100000]\n",
      "Train Loss: 0.3298\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  3%|▎         | 3199/100000 [4:29:35<122:20:27,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3200/100000]\n",
      "Train Loss: 0.0735\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  3%|▎         | 3299/100000 [4:38:02<122:13:03,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3300/100000]\n",
      "Train Loss: 0.0778\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  3%|▎         | 3399/100000 [4:46:29<122:09:06,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3400/100000]\n",
      "Train Loss: 0.0636\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  3%|▎         | 3499/100000 [4:54:56<121:58:27,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3500/100000]\n",
      "Train Loss: 0.1437\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▎         | 3599/100000 [5:03:23<121:51:57,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3600/100000]\n",
      "Train Loss: 0.0488\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▎         | 3699/100000 [5:11:49<121:44:34,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3700/100000]\n",
      "Train Loss: 0.0687\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 3799/100000 [5:20:16<121:32:09,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3800/100000]\n",
      "Train Loss: 0.0670\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 3899/100000 [5:28:43<121:23:35,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3900/100000]\n",
      "Train Loss: 0.0839\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 3999/100000 [5:37:11<121:23:31,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4000/100000]\n",
      "Train Loss: 0.1054\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 4099/100000 [5:45:38<121:20:48,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4100/100000]\n",
      "Train Loss: 0.2341\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 4199/100000 [5:54:06<121:23:18,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4200/100000]\n",
      "Train Loss: 0.2160\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 4299/100000 [6:02:32<121:11:11,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4300/100000]\n",
      "Train Loss: 0.2734\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 4399/100000 [6:10:59<121:15:55,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4400/100000]\n",
      "Train Loss: 0.3621\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  4%|▍         | 4499/100000 [6:19:26<120:57:37,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4500/100000]\n",
      "Train Loss: 0.4306\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▍         | 4599/100000 [6:27:55<120:49:39,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4600/100000]\n",
      "Train Loss: 0.5240\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▍         | 4699/100000 [6:36:21<120:29:35,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4700/100000]\n",
      "Train Loss: 0.1181\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▍         | 4799/100000 [6:44:48<120:24:49,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4800/100000]\n",
      "Train Loss: 0.1191\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▍         | 4999/100000 [7:01:42<119:58:49,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5000/100000]\n",
      "Train Loss: 0.0499\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▌         | 5099/100000 [7:10:09<119:52:41,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5100/100000]\n",
      "Train Loss: 0.0821\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▌         | 5199/100000 [7:18:36<119:50:37,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5200/100000]\n",
      "Train Loss: 0.1068\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▌         | 5299/100000 [7:27:03<119:53:29,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5300/100000]\n",
      "Train Loss: 0.0637\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▌         | 5399/100000 [7:35:30<119:41:43,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5400/100000]\n",
      "Train Loss: 0.0601\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  5%|▌         | 5499/100000 [7:43:58<119:18:11,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5500/100000]\n",
      "Train Loss: 0.0771\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▌         | 5599/100000 [7:52:26<119:20:08,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5600/100000]\n",
      "Train Loss: 0.0757\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▌         | 5699/100000 [8:00:54<119:13:11,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5700/100000]\n",
      "Train Loss: 0.0653\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▌         | 5799/100000 [8:09:21<119:03:29,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5800/100000]\n",
      "Train Loss: 0.1327\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▌         | 5899/100000 [8:17:47<119:04:26,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5900/100000]\n",
      "Train Loss: 0.0500\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▌         | 5999/100000 [8:26:14<119:03:15,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6000/100000]\n",
      "Train Loss: 0.0636\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▌         | 6199/100000 [8:43:09<118:36:14,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6200/100000]\n",
      "Train Loss: 0.0998\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▋         | 6299/100000 [8:51:35<118:33:39,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6300/100000]\n",
      "Train Loss: 0.1246\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▋         | 6399/100000 [9:00:04<118:57:58,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6400/100000]\n",
      "Train Loss: 0.2217\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  6%|▋         | 6499/100000 [9:08:31<118:18:18,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6500/100000]\n",
      "Train Loss: 0.2282\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 6599/100000 [9:16:58<118:03:20,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6600/100000]\n",
      "Train Loss: 0.2776\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 6699/100000 [9:25:25<118:03:28,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6700/100000]\n",
      "Train Loss: 0.3428\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 6799/100000 [9:33:53<118:10:33,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6800/100000]\n",
      "Train Loss: 0.4709\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 6899/100000 [9:42:20<117:31:09,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6900/100000]\n",
      "Train Loss: 0.4413\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 6999/100000 [9:50:48<117:22:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7000/100000]\n",
      "Train Loss: 0.1147\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 7099/100000 [9:59:14<117:29:32,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7100/100000]\n",
      "Train Loss: 0.1220\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 7199/100000 [10:07:41<117:26:14,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7200/100000]\n",
      "Train Loss: 0.0767\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 7299/100000 [10:16:08<117:17:45,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7300/100000]\n",
      "Train Loss: 0.0525\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 7399/100000 [10:24:36<117:14:58,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7400/100000]\n",
      "Train Loss: 0.0913\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  7%|▋         | 7499/100000 [10:33:03<117:03:09,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7500/100000]\n",
      "Train Loss: 0.1063\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 7599/100000 [10:41:29<116:57:20,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7600/100000]\n",
      "Train Loss: 0.0578\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 7699/100000 [10:49:56<116:43:32,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7700/100000]\n",
      "Train Loss: 0.0637\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 7799/100000 [10:58:24<116:32:17,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7800/100000]\n",
      "Train Loss: 0.0718\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 7899/100000 [11:06:51<116:30:22,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7900/100000]\n",
      "Train Loss: 0.0764\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 7999/100000 [11:15:18<116:32:43,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8000/100000]\n",
      "Train Loss: 0.0745\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 8099/100000 [11:23:45<116:11:37,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8100/100000]\n",
      "Train Loss: 0.1376\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 8199/100000 [11:32:12<116:03:57,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8200/100000]\n",
      "Train Loss: 0.0512\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 8299/100000 [11:40:38<116:05:33,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8300/100000]\n",
      "Train Loss: 0.0737\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 8399/100000 [11:49:05<116:12:55,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8400/100000]\n",
      "Train Loss: 0.0612\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  8%|▊         | 8499/100000 [11:57:31<115:37:06,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8500/100000]\n",
      "Train Loss: 0.1019\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▊         | 8599/100000 [12:05:58<115:40:03,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8600/100000]\n",
      "Train Loss: 0.1159\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▊         | 8699/100000 [12:14:27<115:40:51,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8700/100000]\n",
      "Train Loss: 0.2085\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 8799/100000 [12:22:55<115:29:09,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8800/100000]\n",
      "Train Loss: 0.2131\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 8899/100000 [12:31:22<115:16:18,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8900/100000]\n",
      "Train Loss: 0.2776\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 8999/100000 [12:39:49<115:16:07,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9000/100000]\n",
      "Train Loss: 0.3656\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 9099/100000 [12:48:17<115:08:36,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9100/100000]\n",
      "Train Loss: 0.4931\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 9199/100000 [12:56:45<114:50:42,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9200/100000]\n",
      "Train Loss: 0.4427\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 9299/100000 [13:05:12<114:28:15,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9300/100000]\n",
      "Train Loss: 0.1148\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 9399/100000 [13:13:38<114:28:47,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9400/100000]\n",
      "Train Loss: 0.1113\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  9%|▉         | 9499/100000 [13:22:05<114:27:14,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9500/100000]\n",
      "Train Loss: 0.0702\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|▉         | 9599/100000 [13:30:31<114:16:26,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9600/100000]\n",
      "Train Loss: 0.0498\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|▉         | 9699/100000 [13:38:59<114:20:19,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9700/100000]\n",
      "Train Loss: 0.0871\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|▉         | 9799/100000 [13:47:25<113:55:13,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9800/100000]\n",
      "Train Loss: 0.1039\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|▉         | 9899/100000 [13:55:53<113:52:07,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9900/100000]\n",
      "Train Loss: 0.0659\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|▉         | 9999/100000 [14:04:19<114:12:05,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10000/100000]\n",
      "Train Loss: 0.0576\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|█         | 10099/100000 [14:12:46<115:49:37,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10100/100000]\n",
      "Train Loss: 0.0743\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|█         | 10199/100000 [14:21:13<113:28:19,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10200/100000]\n",
      "Train Loss: 0.0750\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|█         | 10399/100000 [14:38:07<113:31:34,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10400/100000]\n",
      "Train Loss: 0.1350\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 10%|█         | 10499/100000 [14:46:34<113:08:05,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10500/100000]\n",
      "Train Loss: 0.0468\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 11%|█         | 10599/100000 [14:55:00<113:02:19,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10600/100000]\n",
      "Train Loss: 0.0707\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 11%|█         | 10799/100000 [15:11:53<112:44:34,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10800/100000]\n",
      "Train Loss: 0.1098\n",
      "Val Loss: 0.1451, Val Accuracy: 0.9437\n",
      "Val F1 (micro): 0.9437, Val F1 (macro): 0.9005\n",
      "Val Confusion Matrix:\n",
      "[[ 91  10]\n",
      " [ 26 513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 11%|█         | 10899/100000 [15:20:21<112:53:07,  4.56s/it]"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "current_lr = lr\n",
    "\n",
    "for epoch in tqdm(range(latest_epoch, latest_epoch + epochs)):\n",
    "    model.train()\n",
    "    \n",
    "    tensor_batch = data_to_tensor_batch(\n",
    "        da.get_batch(),\n",
    "        max_seq_len,\n",
    "    )\n",
    "    tensor_batch.gpu(device)\n",
    "    \n",
    "    labels = tensor_batch.taxes\n",
    "    outputs = model(tensor_batch.seq_ids['input_ids'], tensor_batch.seq_ids['attention_mask'])\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % val_epoch == 0:\n",
    "        train_loss = running_loss / val_epoch\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_cm = evaluate(model)\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Val F1 (micro): {val_f1_micro:.4f}, Val F1 (macro): {val_f1_macro:.4f}\")\n",
    "        print(\"Val Confusion Matrix:\")\n",
    "        print(val_cm)\n",
    "        \n",
    "        # Create metrics dictionary for saving\n",
    "        metrics = {\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\":val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_f1_micro\": val_f1_micro,\n",
    "            \"val_f1_macro\": val_f1_macro,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"lr\": current_lr\n",
    "        }\n",
    "\n",
    "        # Save periodic checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log(metrics)\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(epoch + loss.item())\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Reset training metrics\n",
    "        running_loss = 0\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38a288-ea78-424e-9f90-995c9b435655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _, latest_epoch, metrics = load_checkpoint(model)\n",
    "\n",
    "val_batches_ = [da.get_batch() for _ in range(num_val)]\n",
    "\n",
    "\n",
    "input_sequences_ = [\"ACACAD\"]\n",
    "labels_ = [{0: 1}]\n",
    "\n",
    "def evaluate_df(model):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    df = {\n",
    "        \"sequence\": [],\n",
    "        \"label\": [],\n",
    "        \"pred\": [],\n",
    "        \"loss\": []\n",
    "    }\n",
    "\n",
    "    metrics = {\n",
    "        \"loss\": 0,\n",
    "        \"accuracy\": 0,\n",
    "        \"f1 macro\": 0,\n",
    "        \"f1 micro\": 0\n",
    "    }\n",
    "    \n",
    "    # Process each sequence\n",
    "    for sequence, label in zip(input_sequences_, labels_):\n",
    "        inputs = tokenizer_(\n",
    "            [sequence],\n",
    "            return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_seq_len\n",
    "        ).to(device)\n",
    "    \n",
    "        # Get model output\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "\n",
    "        pred = output.argmax(dim=-1).cpu().item()\n",
    "        loss = criterion(output, torch.tensor([label[0]]).to(device))\n",
    "        df[\"sequence\"].append(sequence)\n",
    "        df[\"label\"].append(level_decoder[0][label[0]])\n",
    "        df[\"pred\"].append(level_decoder[0][pred])\n",
    "        df[\"loss\"].append(round(loss.cpu().item(), 4))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    new_df = pd.DataFrame(df)\n",
    "    new_df['is_incorrect'] = new_df['label'] != new_df['pred']\n",
    "    new_df = new_df.sort_values(['is_incorrect', 'loss'], ascending=[False, False])\n",
    "    new_df.to_csv(f'classification_results__new_att.csv', index=False)\n",
    "\n",
    "    metrics[\"loss\"] = np.array(df[\"loss\"]).mean()\n",
    "    metrics[\"accuracy\"] = accuracy_score(np.array(df[\"label\"]), np.array(df[\"pred\"]))\n",
    "    metrics[\"f1 macro\"] = f1_score(np.array(df[\"label\"]), np.array(df[\"pred\"]), average='macro')  # F1-score for multi-label classification\n",
    "    metrics[\"f1 micro\"] = f1_score(np.array(df[\"label\"]), np.array(df[\"pred\"]), average='micro') \n",
    "    print(metrics)\n",
    "\n",
    "evaluate_df(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb06be5-7f3f-4771-802d-086267ec2df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
