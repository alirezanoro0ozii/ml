{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd53ee37-152c-447c-ad01-0e567857459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dictionary.\n",
      "{'superkingdom': 3, 'genus': 109455, 'order': 1915, 'family': 10413, 'subspecies': 29427, 'no rank': 242062, 'subfamily': 3261, 'strain': 46396, 'serogroup': 154, 'biotype': 17, 'tribe': 2393, 'phylum': 311, 'class': 534, 'species group': 359, 'forma': 699, 'clade': 956, 'suborder': 375, 'subclass': 169, 'varietas': 9991, 'kingdom': 13, 'subphylum': 31, 'forma specialis': 784, 'isolate': 1304, 'superfamily': 901, 'infraorder': 135, 'infraclass': 19, 'superorder': 57, 'subgenus': 1821, 'superclass': 6, 'parvorder': 26, 'begining root': 4, 'serotype': 1229, 'species subgroup': 134, 'subcohort': 3, 'cohort': 5, 'genotype': 22, 'subtribe': 587, 'section': 534, 'series': 9, 'morph': 11, 'subkingdom': 1, 'superphylum': 1, 'subsection': 41, 'pathogroup': 5}\n",
      "\n",
      "Taxonomic ranks sorted by number of taxa:\n",
      "no rank: 242062\n",
      "genus: 109455\n",
      "strain: 46396\n",
      "subspecies: 29427\n",
      "family: 10413\n",
      "varietas: 9991\n",
      "subfamily: 3261\n",
      "tribe: 2393\n",
      "order: 1915\n",
      "subgenus: 1821\n",
      "isolate: 1304\n",
      "serotype: 1229\n",
      "clade: 956\n",
      "superfamily: 901\n",
      "forma specialis: 784\n",
      "forma: 699\n",
      "subtribe: 587\n",
      "class: 534\n",
      "section: 534\n",
      "suborder: 375\n",
      "species group: 359\n",
      "phylum: 311\n",
      "subclass: 169\n",
      "serogroup: 154\n",
      "infraorder: 135\n",
      "species subgroup: 134\n",
      "superorder: 57\n",
      "subsection: 41\n",
      "subphylum: 31\n",
      "parvorder: 26\n",
      "genotype: 22\n",
      "infraclass: 19\n",
      "biotype: 17\n",
      "kingdom: 13\n",
      "morph: 11\n",
      "series: 9\n",
      "superclass: 6\n",
      "cohort: 5\n",
      "pathogroup: 5\n",
      "begining root: 4\n",
      "superkingdom: 3\n",
      "subcohort: 3\n",
      "subkingdom: 1\n",
      "superphylum: 1\n",
      "cuda:1\n",
      "../checkpoints/esm_hierarchy_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys, os, math\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "sys.path.insert(0, '../dlp')\n",
    "from data_process import *\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "epochs= 10_000\n",
    "val_epoch = 50\n",
    "num_val = 25\n",
    "\n",
    "model_name = \"esm_hierarchy\"\n",
    "checkpoint_dir = f\"../checkpoints/{model_name}_checkpoints\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "print(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb2bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM_TaxonomyClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Dictionary of taxonomy levels and their possible classes\n",
    "        taxonomy_levels,\n",
    "        input_dim=320,\n",
    "        d_model=512,\n",
    "        nhead=4,\n",
    "        num_encoder_layers=1,\n",
    "        dim_feedforward=256,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Sequence embedding layers\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layers,\n",
    "            num_encoder_layers\n",
    "        )\n",
    "        \n",
    "        # Shared feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Create classifier heads for each taxonomy level\n",
    "        self.classifier_heads = nn.ModuleDict({\n",
    "            level: nn.Linear(d_model, num_classes, bias=False)\n",
    "            for level, num_classes in taxonomy_levels.items()\n",
    "        })\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # Embedding and positional encoding\n",
    "        # src = self.embedding(src) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        # src = self.pos_encoder(src)\n",
    "        print(src.shape)\n",
    "        src = self.embedding(src)\n",
    "        \n",
    "        print(src.shape)\n",
    "        # Transform sequence\n",
    "        encoder_output = self.transformer_encoder(\n",
    "            src,\n",
    "        )\n",
    "        print(encoder_output.shape)\n",
    "        \n",
    "        # Global average pooling\n",
    "        sequence_features = torch.mean(encoder_output, dim=1)\n",
    "        print(sequence_features.shape)\n",
    "        # Extract shared features\n",
    "        shared_features = self.feature_extractor(sequence_features)\n",
    "        print(\"shared_features:\", shared_features.shape)\n",
    "        # Get predictions for each taxonomy level\n",
    "        predictions = {\n",
    "            level: head(shared_features)\n",
    "            for level, head in self.classifier_heads.items()\n",
    "        }\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb534f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 320])\n",
      "torch.Size([16, 320])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x16 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tensor_batch\u001b[38;5;241m.\u001b[39mseq_ids\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 63\u001b[0m, in \u001b[0;36mESM_TaxonomyClassifier.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(sequence_features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Extract shared features\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m shared_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, shared_features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Get predictions for each taxonomy level\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x16 and 512x512)"
     ]
    }
   ],
   "source": [
    "model = ESM_TaxonomyClassifier(taxonomy_levels=tax_vocab_sizes).to(device)\n",
    "\n",
    "\n",
    "tensor_batch = esm_hierarchy_data_to_tensor_batch('train', random.randint(0, 9999))\n",
    "tensor_batch.gpu(device)\n",
    "\n",
    "input_ids = tensor_batch.seq_ids\n",
    "\n",
    "print(input_ids.shape)\n",
    "predictions = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9630d96-6b98-4224-bf1e-482605688b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 240.627968 M parameters\n"
     ]
    }
   ],
   "source": [
    "total = sum(importance_dict.values())\n",
    "level_weights = {key: value / total for key, value in importance_dict.items()}\n",
    "\n",
    "model = ESM_TaxonomyClassifier(taxonomy_levels=tax_vocab_sizes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"model:\", sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962c2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def train_step(level_weights=None):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Get batch and convert to tensor\n",
    "    tensor_batch = esm_hierarchy_data_to_tensor_batch('train', random.randint(0, 9999))\n",
    "    tensor_batch.gpu(device)\n",
    "\n",
    "    input_ids = tensor_batch.seq_ids\n",
    "\n",
    "    print(input_ids.shape)\n",
    "    predictions = model(input_ids)\n",
    "    labels = tensor_batch.taxes\n",
    "    \n",
    "    # Initialize total loss\n",
    "    total_loss = 0\n",
    "    level_losses = {}\n",
    "\n",
    "    # Calculate loss for each level\n",
    "    for level, pred in predictions.items():\n",
    "        level_loss = F.BCEWithLogitsLoss(pred, labels[level])\n",
    "        \n",
    "        # Apply level weights if provided\n",
    "        if level_weights and level in level_weights:\n",
    "            level_loss *= level_weights[level]\n",
    "            \n",
    "        level_losses[level] = level_loss.item()  # Store loss value for logging\n",
    "        total_loss += level_loss\n",
    "    \n",
    "    # Backward pass and optimization step\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return total_loss.item(), level_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12c4dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tax_vocab_sizes, level_weights=None, num_val_batches=1):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    level_losses = {} \n",
    "    total_loss = 0\n",
    "\n",
    "    # Initialize accumulators for each level\n",
    "    level_correct = {level: 0 for level in tax_vocab_sizes.keys()}\n",
    "    level_total = {level: 0 for level in tax_vocab_sizes.keys()}\n",
    "    level_preds = {level: [] for level in tax_vocab_sizes.keys()}\n",
    "    level_labels = {level: [] for level in tax_vocab_sizes.keys()}\n",
    "    \n",
    "    # Only track confusion matrix for \"begining root\"\n",
    "    root_preds = []\n",
    "    root_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for _ in range(num_val_batches):\n",
    "            tensor_batch = esm_hierarchy_data_to_tensor_batch('val', _)\n",
    "            tensor_batch.gpu(device)\n",
    "            \n",
    "            predictions = model(tensor_batch.seq_ids)\n",
    "            labels = tensor_batch.taxes\n",
    "            \n",
    "            batch_loss = 0\n",
    "            batch_level_losses = {}\n",
    "\n",
    "            # Calculate loss for each level\n",
    "            for level, pred in predictions.items():\n",
    "                level_loss = F.cross_entropy(pred, labels[level])\n",
    "                # Apply level weights if provided\n",
    "                if level_weights and level in level_weights:\n",
    "                    level_loss *= level_weights[level]\n",
    "                \n",
    "                batch_level_losses[level] = level_loss.item()\n",
    "                batch_loss += level_loss\n",
    "            \n",
    "                # Store predictions and labels for F1 calculation\n",
    "                predicted_classes = torch.argmax(pred, dim=1)\n",
    "                level_preds[level].extend(predicted_classes.cpu().numpy())\n",
    "                level_labels[level].extend(labels[level].cpu().numpy())\n",
    "                \n",
    "                # Store predictions and labels for \"begining root\" confusion matrix\n",
    "                if level == \"begining root\":\n",
    "                    root_preds.extend(predicted_classes.cpu().numpy())\n",
    "                    root_labels.extend(labels[level].cpu().numpy())\n",
    "                \n",
    "                # Accumulate correct predictions and total samples for each level\n",
    "                level_correct[level] += (predicted_classes == labels[level]).sum().item()\n",
    "                level_total[level] += labels[level].size(0)\n",
    "            \n",
    "            # Update total loss and level-specific losses\n",
    "            total_loss += batch_loss.item()\n",
    "            for level, level_loss_value in batch_level_losses.items():\n",
    "                if level in level_losses:\n",
    "                    level_losses[level] += level_loss_value\n",
    "                else:\n",
    "                    level_losses[level] = level_loss_value\n",
    "    \n",
    "    # Calculate average losses\n",
    "    val_loss = total_loss / num_val_batches\n",
    "    level_losses = {level: loss / num_val_batches for level, loss in level_losses.items()}\n",
    "    \n",
    "    # Calculate accuracy for each level\n",
    "    level_acc = {level: correct / total if total > 0 else 0 \n",
    "                 for level, (correct, total) in \n",
    "                 zip(level_correct.keys(), zip(level_correct.values(), level_total.values()))}\n",
    "    \n",
    "    # Calculate F1 scores for each level\n",
    "    level_f1 = {level: f1_score(np.array(level_labels[level]), \n",
    "                               np.array(level_preds[level]), \n",
    "                               average='micro') \n",
    "                for level in tax_vocab_sizes.keys()}\n",
    "    \n",
    "    # Calculate confusion matrix only for \"begining root\"\n",
    "    total_cms = {\"begining root\": confusion_matrix(np.array(root_labels),\n",
    "                                                 np.array(root_preds),\n",
    "                                                 labels=[_ for _ in range(tax_vocab_sizes[\"begining root\"])])}\n",
    "    \n",
    "    # Calculate overall accuracy across all levels\n",
    "    total_correct = sum(level_correct.values())\n",
    "    total_samples = sum(level_total.values())\n",
    "    overall_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    \n",
    "    model.train()  # Set the model back to training mode\n",
    "    return val_loss, level_losses, overall_accuracy, level_acc, level_f1, total_cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f21f4b4-1f5b-43ce-9512-af44c8a53454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 320])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x16 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_f1s \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 9\u001b[0m     train_loss, level_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m val_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(level_weights)\u001b[0m\n\u001b[1;32m     12\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tensor_batch\u001b[38;5;241m.\u001b[39mseq_ids\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m tensor_batch\u001b[38;5;241m.\u001b[39mtaxes\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Initialize total loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 60\u001b[0m, in \u001b[0;36mESM_TaxonomyClassifier.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     57\u001b[0m sequence_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(encoder_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Extract shared features\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m shared_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Get predictions for each taxonomy level\u001b[39;00m\n\u001b[1;32m     63\u001b[0m predictions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     64\u001b[0m     level: head(shared_features)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m level, head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier_heads\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     66\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x16 and 512x512)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_f1s = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, level_losses = train_step(level_weights)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (epoch + 1) % val_epoch == 0:\n",
    "        val_loss, level_losses, acc, level_acc, level_f1, cms = evaluate(tax_vocab_sizes, level_weights, num_val)\n",
    "        print(\"cms\", cms)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(acc)\n",
    "        val_f1s.append(level_f1)\n",
    "\n",
    "        mean_train_loss = sum(train_losses[-val_epoch:]) / val_epoch\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {mean_train_loss:.4f}, Val Loss: {val_loss:.4f}, val acc: {acc:.4f}\")\n",
    "        print(sum(level_f1.values()) / len(level_f1))\n",
    "    \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_step_{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'accuracy': acc,\n",
    "            'f1_score': level_f1\n",
    "        }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3448896f-7820-4e7a-9be6-a5f3908e2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_checkpoint(checkpoint_dir, model, specific=None):\n",
    "    # List all checkpoint files and sort them by step number\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"checkpoint_step_\")]\n",
    "    if not checkpoints:\n",
    "        print(\"No checkpoints found in directory.\")\n",
    "        return None\n",
    "\n",
    "    # Find the latest checkpoint based on step number\n",
    "    checkpoints.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]), reverse=True)\n",
    "    if specific is None:\n",
    "        latest_checkpoint_path = os.path.join(checkpoint_dir, checkpoints[0])\n",
    "    else:\n",
    "        latest_checkpoint_path = os.path.join(checkpoint_dir, specific)\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(latest_checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    train_loss = checkpoint['train_loss']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "    accuracy = checkpoint['accuracy']\n",
    "    f1_score = checkpoint['f1_score']\n",
    "\n",
    "    print(f\"Loaded checkpoint from epoch {epoch+1}\")\n",
    "    \n",
    "    return {\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45da7505-9ea8-4b10-9ccf-88f41ae46b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 10000\n",
      "begining root \t cellular organisms\n",
      "superkingdom \t Bacteria\n",
      "--------\n",
      "cellular organisms, Bacteria, Pseudomonadota, Betaproteobacteria, unclassified Betaproteobacteria, Betaproteobacteria bacterium GR16-43\n",
      "begining root \t cellular organisms\n",
      "no rank \t unclassified Betaproteobacteria\n",
      "superkingdom \t Bacteria\n",
      "phylum \t Pseudomonadota\n",
      "class \t Betaproteobacteria\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../dlp')\n",
    "\n",
    "from data_process import *\n",
    "\n",
    "test_seq = \"MKRLRPSDKFFELLGYKPHHVQLAIHRSTAKRRVACLGRQSGKSEAASVEAVFELFARPGSQGWIIAPTYDQAEIIFGRVVEKVERLSEVFPTTEVQLQRRRLRLLVHHYDRPVNAPGAKRVATSEFRGKSADRPDNLRGATLDFVILDEAAMIPFSVWSEAIEPTLSVRDGWALIISTPKGLNWFYEFFLMGWRGGLKEGIPNSGINQTHPDFESFHAASWDVWPERREWYMERRLYIPDLEFRQEYGAEFVSHSNSVFSGLDMLILLPYERRGTRLVVEDYRPDHIYCIGADFGKNQDYSVFSVLDLDTGAIACLERMNGATWSDQVARLKALSEDYGHAYVVADTWGVGDAIAEELDAQGINYTPLPVKSSSVKEQLISNLALLMEKGQVAVPNDKTILDELRNFRYYRTASGNQVMRAYGRGHDDIVMSLALAYSQYEGKDGYKFELAEERPSKLKHEESVMSLVEDDFTDLELANRAFSA\"\n",
    "tax_lineage = \"cellular organisms, Bacteria, Pseudomonadota, Betaproteobacteria, unclassified Betaproteobacteria, Betaproteobacteria bacterium GR16-43\"\n",
    "\n",
    "model = TaxonomyClassifier(taxonomy_levels=tax_vocab_sizes).to(device)\n",
    "latest_checkpoint = load_latest_checkpoint(checkpoint_dir, model)\n",
    "\n",
    "input_tensor = torch.LongTensor([encode_sequence(test_seq)]).to(device)\n",
    "output = model(input_tensor)\n",
    "\n",
    "output_indexes = {k: v.argmax().item() for k,v in output.items()}\n",
    "\n",
    "hierarchy = [\n",
    "    \"begining root\", \"no rank\", \"superkingdom\", \"kingdom\", \"subkingdom\", \"superphylum\", \"phylum\",\n",
    "    \"subphylum\", \"superclass\", \"class\", \"subclass\", \"infraclass\", \"superorder\", \"order\", \"suborder\",\n",
    "    \"infraorder\", \"parvorder\", \"superfamily\", \"family\", \"subfamily\", \"tribe\", \"subtribe\", \"genus\",\n",
    "    \"subgenus\", \"species group\", \"species subgroup\", \"species\", \"subspecies\", \"varietas\", \"forma specialis\",\n",
    "    \"forma\", \"biotype\", \"pathogroup\", \"serogroup\", \"serotype\", \"isolate\", \"strain\", \"genotype\", \"clade\",\n",
    "    \"cohort\", \"subcohort\", \"section\", \"subsection\", \"series\", \"morph\",\n",
    "]\n",
    "\n",
    "def pretty_print(dict_index):\n",
    "    for k in hierarchy:\n",
    "        if k in dict_index:\n",
    "            v = dict_index[k]\n",
    "            if v > 0:\n",
    "                print(k, \"\\t\", level_decoder[k][v])\n",
    "\n",
    "\n",
    "def decode_input_lineage(tax_lineage):\n",
    "    print(tax_lineage)\n",
    "    test_input = encode_lineage(tax_lineage)\n",
    "    for k in hierarchy:\n",
    "        if k in test_input:\n",
    "            v = test_input[k][0]\n",
    "            if v > 0:\n",
    "                print(k, \"\\t\", level_decoder[k][v])\n",
    "\n",
    "\n",
    "pretty_print(output_indexes)\n",
    "print(\"--------\")\n",
    "decode_input_lineage(tax_lineage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
