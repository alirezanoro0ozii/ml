{0: 4, 1: 35, 2: 1368, 3: 6024, 4: 4330, 5: 5265, 6: 5453, 7: 15592, 8: 65895, 9: 59786, 10: 54221, 11: 141660, 12: 20431, 13: 13635, 14: 17392, 15: 32172, 16: 35581, 17: 34356, 18: 33115, 19: 43504, 20: 61510, 21: 57903, 22: 31214, 23: 32835, 24: 107520, 25: 82492, 26: 96471, 27: 90666, 28: 85207, 29: 70508, 30: 71902, 31: 26728, 32: 11716, 33: 6444, 34: 2510, 35: 872, 36: 4}
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable parameters: 755.969937 M
Total parameters: 1408.326438 M
ESM1b(
  (esm): EsmModel(
    (embeddings): EsmEmbeddings(
      (word_embeddings): Embedding(33, 1280, padding_idx=1)
      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (position_embeddings): Embedding(1026, 1280, padding_idx=1)
    )
    (encoder): EsmEncoder(
      (layer): ModuleList(
        (0-32): 33 x EsmLayer(
          (attention): EsmAttention(
            (self): EsmSelfAttention(
              (query): Linear(in_features=1280, out_features=1280, bias=True)
              (key): Linear(in_features=1280, out_features=1280, bias=True)
              (value): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (output): EsmSelfOutput(
              (dense): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
          (intermediate): EsmIntermediate(
            (dense): Linear(in_features=1280, out_features=5120, bias=True)
          )
          (output): EsmOutput(
            (dense): Linear(in_features=5120, out_features=1280, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    )
    (pooler): EsmPooler(
      (dense): Linear(in_features=1280, out_features=1280, bias=True)
      (activation): Tanh()
    )
    (contact_head): EsmContactPredictionHead(
      (regression): Linear(in_features=660, out_features=1, bias=True)
      (activation): Sigmoid()
    )
  )
  (heads): ModuleDict(
    (0): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=4, bias=True)
    )
    (1): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=35, bias=True)
    )
    (2): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=1368, bias=True)
    )
    (3): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=6024, bias=True)
    )
    (4): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=4330, bias=True)
    )
    (5): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5265, bias=True)
    )
    (6): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5453, bias=True)
    )
    (7): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=15592, bias=True)
    )
    (8): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=65895, bias=True)
    )
    (9): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=59786, bias=True)
    )
    (10): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=54221, bias=True)
    )
    (11): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=141660, bias=True)
    )
    (12): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=20431, bias=True)
    )
    (13): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=13635, bias=True)
    )
    (14): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=17392, bias=True)
    )
    (15): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32172, bias=True)
    )
    (16): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=35581, bias=True)
    )
    (17): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=34356, bias=True)
    )
    (18): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33115, bias=True)
    )
    (19): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=43504, bias=True)
    )
    (20): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=61510, bias=True)
    )
    (21): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=57903, bias=True)
    )
    (22): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=31214, bias=True)
    )
    (23): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32835, bias=True)
    )
    (24): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=107520, bias=True)
    )
    (25): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=82492, bias=True)
    )
    (26): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=96471, bias=True)
    )
    (27): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=90666, bias=True)
    )
    (28): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=85207, bias=True)
    )
    (29): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=70508, bias=True)
    )
    (30): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=71902, bias=True)
    )
    (31): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=26728, bias=True)
    )
    (32): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=11716, bias=True)
    )
    (33): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=6444, bias=True)
    )
    (34): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2510, bias=True)
    )
    (35): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=872, bias=True)
    )
    (36): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=4, bias=True)
    )
  )
)
  0%|          | 109/100000 [12:35<53:35:06,  1.93s/it] 
Epoch [10/100000]
Train Loss: 238.4409
Train Loss: 99.2966
Epoch [20/100000]
Train Loss: 85.9625
Train Loss: 76.2752
Epoch [30/100000]
Train Loss: 66.7664
Train Loss: 70.1306
Epoch [40/100000]
Train Loss: 70.1216
Train Loss: 66.3870
Epoch [50/100000]
Train Loss: 64.8833
Train Loss: 61.6367
Epoch [60/100000]
Train Loss: 61.0211
Train Loss: 58.1877
Epoch [70/100000]
Train Loss: 58.9309
Train Loss: 56.3582
Epoch [80/100000]
Train Loss: 59.3916
Train Loss: 56.1880
Epoch [90/100000]
Train Loss: 54.0478
Train Loss: 55.0918
Epoch [100/100000]
Train Loss: 51.1016
Train Loss: 53.4605
Epoch [110/100000]
Train Loss: 50.0201
Train Loss: 53.5012
Epoch [120/100000]
Train Loss: 53.1629
Train Loss: 51.3290
Epoch [130/100000]
Train Loss: 49.6413
Train Loss: 50.1095
Epoch [140/100000]
Train Loss: 46.4036
Train Loss: 49.8763
Epoch [150/100000]
Train Loss: 46.3028
Train Loss: 48.7854
Epoch [160/100000]
Train Loss: 53.2040
Train Loss: 47.7518
Epoch [170/100000]
Train Loss: 43.9915
Train Loss: 47.1148
