  0%|          | 9/100000 [00:18<53:40:13,  1.93s/it]
labels: [ 235466  139064  775532    4621 1220594 1003684  733090  509505  178378
  179652  413629   19029   17860  825235    2391  818462   15810   70419
  823371   39306    9901  627579  426900   17257  156243  217019  652976
    9849  127055    6456    1484 1157858  406755 1199697   44936  448538
 1183830   22469     312      82   83812  747411  718522   47244 1250332
   25094   25838  279314  780263   21042  502244  352084   68529    3979
  811470  687679  223731    3547  353150    4304 1190061   43670  141094
  995248   86183   24802  747411  995428     658     317 1129939   73796
  172230  531393  811538  810390   20895  237639     738   20891    1047
  393985  321670  310798     288   30593  346390  311069  455219      95
   78468  131285   33026  775556  690167  169617   78768  399593  198837
  384733  483911    7560  841486  138596  741756  249527     686    3530
  978566   79285  387089  168779  826062    5326     189  393472  204421
  718522   31269 1262951  500468  295775 1185996  666869  413924  718522
  717196  470584    2273   28771 1239073     305  810357    7375 1128157
  230459    3578  747411   59692  602904  809281  774613  539221  719189
  682880  386758  690145   81782  719798    2744     305  732757  709959
  697919    4199  256284  994762  374716  826042   33240 1234351  345458
  199438  658739  352086  162322 1094881 1274271 1198145 1157922 1237385
  346390   50998  718535   89983 1124673  412364 1242309  653094  165240
 1205741 1124405  122371   43640  466328     941  667753   95796  445783
  125321   17746  912413 1141431  808032  519837  223553  346604  509501
  828460  387002  811479  816394  749987  443348  811475  596294  127349
 1228214  479456  810351  455279  452667  257661   13827  230544  824252
 1135038    7375  925409 1197279  682643  778106  719142  476667  181711
  255489  210405  978578    4072  810356    1970    3727 1195827    4225
 1244974  397857  736299   27320    9834   15007     382     360   40021
  911292 1212415  205819  346623  813613    1182   17063  527951   40555
   14199  690608  274653   35078  771268  562018   45880   24263  123365
  771743   75670  111875 1141774  728197    8887  819669  536009  397975
  811544 1250050     680    4268  604750 1198588   43858    1546     665
 1206622  446243  526959    1072  599694   97968  353132  811470  250359
  777474 1245198  772904   38234   17063  101413  480472  642099  926053
   29294 1241401   41305  995343   36338  826062  580261  338577  826376
    6739 1204193  158488  802988    2273 1094674   57127 1225060  385139
   39850  811470 1229821    1111  777582    9856  771189  273153  747411
  387047  737675  244158   21959  747411  451799  163806   84588  284917
   42765  320304     245  374715    4332  682954   63420  674961 1170032
  732237  811521     760   88222   89361   21959  140864 1225071   17094
  747411  215963      95  354063    1905  297675    3609   60501 1207481
  432411  737674    1830   27641  197720     730    8992    3248     381
  810388 1134553  404316  775072  825261     944   15840   43226 1199610
 1183671  481012  744716    7707  189664   97015    6261   25745  811501
  695354  822232  682721 1183564  755955  987187     338    6795  827263
  100554  653207    2278  652989  275678  666875  111533  158488  814938
    5369   57752  122371  682583  287924    1883  453943 1133850   22371
  283349  596490  155540  811480  309107  599688 1148725  193060  134217
  434393  158488    5326 1218347  425606   80467  686508   18241    3054
   19692  742265  147577   26390   24565  811460  978566  185704    7396
    3587   71895 1265444    8635  250171  458015  810356    4376 1206146
  725958  158486  261459  732266  258980     144    3959   10859  811460
    1853  597304   19029 1137905   13013  353346  736472  747411   75694
  822235  216515  811300  117612  355441  158243  811520    2928  460113
    3238   71451  284128  330750    7228  544823    7446  344369  535270
  536608   45045  771865     149    1945  446040     609   91008   18457
  100260  916614 1206058  318446 1225799   22051     353  711422     312
   40425    9248    6684  774611  116962    4405 1134513  214187 1262845
     784 1240784   21269    4119 1004752   40425    3688   13417   42371
  360953 1173863  820246  742265  334622  523005  435571  223423  351227
  180642 1231855  799613  425058   24577     697    2254  444124  799091
 1143653  506170  748171   50304  412483  402748    9104  460488   20124
  857328   83025   99392   14602 1141778  123774  183132     308  708891
   35156   10783     707     250  333594   70575  827875  718535  123365
  237469  596887    6745  778106  345002  710047    4241  934509  747410
    4000  535270   24852  771265    2370   50807    1640  747553 1210211
  813100  724365  156776  263434      69  822229  432311   26377   11996
  131623  682953  727353     144  709919  183730  136705  146233  814938
     579     765  466265  687469  191639 1206054   90070     784     125
 1226341  750709    7418   12570  472241 1214916  698680    4966    2964
  169012  995425  127884  160700  437668    9772    2310     360 1013731
 1244968    1137  811542    5326  128636    7082  458015  600306    3625
  727353]
preds: [811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520  13591 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520   2384 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520]
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
labels: [  645 15565 43377  2676   138   256   305 49250  3666   136  1378 44183
  7369 23231 39080 42145  4188   141 19359  3605  9665  9393 35358 17885
 10846 17879    76 42065  2374  6696 17886 17881 47834   161  6735   135
  5670 17670 50422 49671 18929   287  6898   118 51722  6284  3666 32905
 49535  2437  5672    57  4714 20137 18696 44185  8773 29759 14150  2515
  6403  2344 43877   184 10666   419   287   295  4459   129 17671 27756
   484 10785  9831 23232   145  4880   304   145   370 20300   129  6219
   100 10458  5874 49641   390  9665    76 16805  3669 43377 29946  6804
 21514    67 38616   384 20300 19462 18885 48500 11283  3721 11278 49029
   244  1080 16778  3574 43034 24755    88   272  4507  6898  2271 17881
   258  1225   379   371   390  6898 30897 17881  1100  3574   156   129
 30013 14635 19596 42144 31677   287    43  4181  4167  6624   390 26027
  9829 10838 26913  5674 10846  4320   129  3565 28522  2210  2465 45325
 26313  1226  9813  4181 42607 44952    79   120 10385  9961  4191   377
   523 48317 43627  5874     0  9245 49292  5544 32777    76    90 27194
 43799    76 49029  2344  1187 17879  4168 42079   151  9219  3640 10532
 43650   390 49469  3549 18177 49256  9052  6219 23644    89   463 18228
 11210 41770  4172 38780 30897 21952  9245   421 10838  2355    89  8342
 31765 14635 46366 11340 43378  8040  2836 43877 27194  1243   156   488
  2384 22055 16260  2205 17877  2475 49670  7645  9927 50239 15366 51188
   161 10793   284 12878  9744 10042   137 16790   419  3137 17872  9663
  1220   131   390  1566  3666  5674  1177   419   183  9961  1359  4475
 13462  9960  4407    63 11760   400 42934    79 11278 25130   400  4182
  1186 21524  4459  5672 48482 10386 10847 21524 17871  1243 18696 13433
   283   130  4183 36189  3137 17035 48499   370 11211 12809 14565  3666
 12126  4181 43034   797 31869   323 49533   419  6297 14565  1100 19909
   400   390   305 13462 18696   118 32197 17881   354  7954   100   287
   109    44 32022  3491   287 16804  3574  4498  2765  1177 28265   105
 17819  2534 37563 13462  6219 10846   323 22049 17877 17877 17671  3491
  6219   390  2437   287 11056  9665 49677 16260 48499 32388  1670  6624
  7085  4172 36026  8126  6219   304 10846  1868   161 10825  9245 32621
  5462 32739 17878 31677 12960  9961   390   157   100  1885  4436  6762
  1015 41025  8644 14905  4188 18696   390 28321   108   146 47003  9572
 49113    76 42109 10786 32179 10786 45228  6297  9230 24755   118 49029
  3565 10554 34257   377  4475 29759   212 43377  4178  4185   390 49216
  7923 44183 15444  6219  6297 24755 47806 18047   166 18716 30431  1653
  1310  4178 32403 22526   390 35436   244   268 44184 17539  4447  4178
  3536 13182 17881 22055  3444 10836   268  6297  5524 28017  3574    76
  2307  1681 35436 35675 13462 44183 20300  5499 31733   186   287 21514
 43054 17881   390  5789 11503 18227 18856  4074   323  5449  1771  5672
   138  1653 17877 45227   184  9815 31781 35211    43    76 16266   329
 44059 50432  4931 14635   523    95 48324     0 16805 44187   390 50422
   400 19462   183 21274 34673 25102  9245    68  3583   323  3574 17881
  3918 23664   400  2177  6014 29423    63  9662   339  4178 28546  6219
 49543 10838    92   100  3583     2   421   419   304 42100  9384   109
 32519   322  9662 11056 50542  4507   108  2765 16266  6898 10847 13462
 17872 13462 13462  3358   129   356   390 17883   304   109   147 45352
     0  9245   183   421 24844 45481  8040 27961  9831  2479 44842  3564
  2332  9815   419  3666     0 14459   661 16233 42144    10   289   442
 21357    47   118 21332 41496 13508 29945  6469   369    76   225 30897
   120 44846  9230  9964   323   416  5462   193    95  9396   323 49364
 22059    90   156 10064 37793 17877  8342  5395  1560 10531   295 32777
  2654  3666 35209  1125 10793 49292   390 32197 43440 24755 50239   400
 17881  7008  2141   369]
preds: [  419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419  2093   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419   419   419
   419   419   419   419   419   419   419   419   419   419 14565   419
   419   419   419   419   419   419   419   419   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390   390   390   390   390   390   390   390   390
   390   390   390   390]
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Epoch [10/100000]
First Position Metrics:
Train Loss: 2.5676
Train Accuracy: 0.0016
Train Precision (micro): 0.0016, Train Precision (macro): 0.0000
Train Recall (micro): 0.0016, Train Recall (macro): 0.0017
Train F1 (micro): 0.0016, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 2.5676
Train Accuracy: 0.0094
Train Precision (micro): 0.0094, Train Precision (macro): 0.0001
Train Recall (micro): 0.0094, Train Recall (macro): 0.0019
Train F1 (micro): 0.0094, Train F1 (macro): 0.0001

labels: [1134516 1260769    1859 ...  903622  292839 1227760]
preds: [811520 811520 811520 ... 811520 811520 811520]
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
labels: [ 9245  4178 35713 ... 14482   329  1173]
preds: [390 390 390 ... 390 390 390]
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
First Position Validation Metrics:
Val Loss: 12.2580, Val Accuracy: 0.0028
Val Precision (micro): 0.0028, Val Precision (macro): 0.0000
Val Recall (micro): 0.0028, Val Recall (macro): 0.0004
Val F1 (micro): 0.0028, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 12.2580, Val Accuracy: 0.0241
Val Precision (micro): 0.0241, Val Precision (macro): 0.0000
Val Recall (micro): 0.0241, Val Recall (macro): 0.0008
Val F1 (micro): 0.0241, Val F1 (macro): 0.0000
--------------------------------------------------------------------------------
  0%|          | 9/100000 [01:14<229:00:43,  8.25s/it]
  0%|          | 9/100000 [00:17<53:39:03,  1.93s/it]
labels: [1225813  113573 1206411  604533  811484 1135255    2281  159012  994730
 1004400   11816  455407    4332  559391 1225134 1267491     326  607528
 1214312   22371   51225  743537    4386   67926 1128157  136323  727353
 1274282   34876   46494     154  509513  709285  778182    2256    4200
  717196    8051     189  554206  226178  170454 1128834   28179  747411
     305  364427  367398  135345  912252  635553  252917   19041  718441
  717199   28978  718539 1132839  295547  446151    1819  363479    1637
   12611  480383     305  736285    2658  725939  827342  266501  281907
     920  653121     784 1003269  470763   28533  804539  709226    6149
  811461  687774  123584  737675  666880  727353  686655   84634  445177
   21811  324798  369722  191643  109155  746446  656527  100233  387082
  640619  135540  685815 1003277  811470   70716  250716  213301   71941
  451403  910820 1250333  604921 1200878  451733  166823  732757  404682
  264015 1225080   62030  334202  995337  811487 1204128    3553  504400
 1245195   10532   27002  512455  673742  349343 1199578      85  737675
  248740  678172  426673  266737   51469  603046  571937    1092   23458
  288646     757  387546 1235614  571372  761265  775086   10549  519658
 1204128    2273  718522   28789  561028     236  635111  110573  995322
      21  811492 1135110    1822  910968   12416  297112  746869  509560
   15390  803941  163044  318481  747411  689755  811470  166823    1819
  406397 1232880   39776  706255    5326  623980  232703   12570    3528
 1003451     449    1883    3644   14025  749044  810383 1237847   51814
  911292  343932   16670  652954  518855 1229250    2665  499062  743187
  138280  641998  710021    6420  226266    3609 1128304   11141    5326
 1240486  810340  811470  414411     342  313135  340771   38766 1224959
   20391  481474 1183830  224697 1215374   18100     702  384734  340420
  836437  783109   12541  825988  276695  569279  727353  194432    1137
  652965 1221234     362  529366  768461  159946  416113  826021    3238
    3550  159011  811519  415219 1214749  426733  406756    2281  466328
   11426  544596   60517    1819  349717 1250324   63002  230113 1183283
   80720  737675  425678  482713    2671  653195  823102  457106  812567
  605124  986615  658465   31618  180640   13434 1049761   42940  325795
  112514  811538  112547   17063  185486 1238732     312   62148  317442
    5326  110669   11638  343286 1225908  397967  569305  826006  659480
  772983   31014  214832   75861    9911  182230  750500  652988    6724
    1792  147849  811480  925917  446233  134731  171302  903468 1211967
 1127683   36002  433591  727353  747411  133881     158  883473 1241911
  555293  182425 1129586  808481     545   61133  683726 1247556   13591
  569195   75387 1273207  246788   13412 1013825  145535  856899  464507
  800362  841640  423590 1157886  294871    3228 1148827  719799  770019
  682592 1222824  227205  744717  330757  512425  341810   39231  761239
  197356  811479   95199  826098  825235     305  934510    7089  782222
     563     295  422322   12986  599685  994762  611295  778106  506437
  352877  175233  333020   11981  823108  811487 1252940  746036 1274557
 1134560  961889    8729  156900   56058  347983   24962   88528  532871
  380391  621905 1199317  810390    1022  210328  296609  727353 1215137
  214186  233301   60413    5161   53409  515478  747411 1128833    2959
  256656  808483  750324  811470  887846 1210341   34070  460535  709225
  200254  682375    3942     757   14490   89619  742403  737673  514595
  759150  810337  552894  149976  316539  406859  536933  249343  635757
  610302  813535  454809  451409  509428    7227  150855      95   15838
   14755 1253583  925773  249637 1079372  810388  504962   31185    2271
   46250  223424  733090 1227417 1204335  551369 1229224   23129  719146
   71602  818233   11955 1127764  568833  813613 1229632 1135854  255645
  133180    4028    1945  811480  813523     149  857369 1225115  539789
  737622  635120  511265 1255232  567221    5947  159547  727353  351157
  387546  175266  763450  747410  811504 1262867   39961 1225800  131061
   11743   20360  197356    3788 1239971  552875  743325  995626  472773
 1251988  433960  445832  136573   36664 1225072 1250725  803049  160241
    4213  116919  128229    1922  656545     416  208871  641998   45880
 1212669  864565 1128843  447065   51134 1184891    8007   46696  199844
    2038  568108    3296  147301 1241907   11155  925775  194836  357773
     295   75672  765795  962110 1229231  994816  703220  961910    6391
  726996 1181057  341807   79299  549978  995244  710003   49365    3728
   59337  320048 1201242  141092  994914  777987    3528  697618   90844
  508731  341837  497003    5326  635141   21656 1244964  416448  804544
     312  868941 1003942  520366  747564  428602  738323    4468     848
  189706     671  961889  811480  411224  195054    8051  926053  744717
  711730  253633    1293    4095  182599    6423   31269  837158    3908
    2951 1126725  325517 1245201  233540  813613   44120  656658     155
  272141   28615  551287   18520 1158209  994728  117952  868939  813613
   95605]
preds: [811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 811520 811520 811520 811520 811520 811520 811520 811520
 811520 811520 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 803909 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411
 747411 747411 747411 747411 747411 747411 747411 747411 747411 747411]
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
labels: [  390 49671   286   369  3664 10683 42108 49671   184   390 24864   118
  2534 10838   390  6594  3666 43799     0 29759  5474 27994  2570  3666
 19596   371   369  2341  7982 22379 14565   339    76 18895 42100  2465
 30897  7780    88  3549 40844   356   390 34387   287   129 48501  6898
 10785   390   390  1315 19684  6219     2 42100 10385  9245 31276 30430
 19462 27194  3759  6270  7551   129    11  1258   260 23457   156 10063
  4459 30733   323 23236  1359 10846 47738  4453  5674 19372 39918   419
    44   189   369 49310   156 29170 15216 29108  4465   129 51194    66
 40944 14635  3566   455  2948 18891 17872 18696 11056 34707 17877 42105
   379 17877 17478 45197  7763 20946 27194  3565 10846 49525   390 22177
 49210   329 14946 10785 29759 40413   130  2476 23580   234 13462  4465
    90  9666    44 50239  5085   100 20985  7780   474  5541  3549 21700
 50197   323 44338    76 48520   323 18891  3893    76 10785  1100  6898
     2 42065   104 23644  9961   329 20148  9393  3569 19463   356 21127
 22858 17872   339    76 28522  1222    57   287 44605 18696 27194 19462
  2765 48645 27119    88 24755 16159 50239 10064 49029   402   183 34257
 16786  4882    93  8641 22181   156 12878 48520  3551  6583   524   390
 41494  3792 17881 49216   390 18856 36189 14565 32388   256   160 24755
  5674 26113 18696 32466   129 39651   100  1527 31010  6219  6898  5670
   135 10825  7437   304   379  5672 27973   283 44185 19360  1352    76
   369 46579 32197    95 13290 10793 10683   390    30 22033 39838  5449
 29759   151    40  3666   419   131 37383 42108  1187  5789 48499     0
 19462 38613 13461 16234 10042  2651 13961    44 51878  7413  5994    25
 16792   103 31010 43810  7923   385   416 51951   370 46731  1086 10180
  7146  9831   419  3137   184   135 50422 14099 13463 24755 10847  5283
 25032  1359 34319 27657 30301 41268 18893 13462 30057 49364 17877 25032
 43442 11846   156 38731   150  4185   390   184 49585 48499  9831 17877
    49  1425 19462   369   287 24945    76  4376 45325 50599  7118   522
   118  6898  2437    40 27186 22177 23123 14565   390   585 50485    12
 21515   440 20300 47495   189 13462    40 15325 11743 10838   421 44183
  3565  9342 14565    87   305  1244    63    78   161  4181 23644 15510
 18878 23231   129 44556   129   286   233   130 27346 23671   323 26313
 19983  8040   522  2765  4045  1426   360 35365 14946 20506    42   377
  9245 11656 27683  8235   419    76 24864   258  7923 13131 42067 34427
 23232   371   370 44303   369    89    68   172 14565 43884 17872  2757
   287   390  1551 32575 10785  6219 18696 46023 44840 11239 44303 11242
 31010 10785  2300   323 11278 21854  4181 17872   403 19360 38779 49677
 26259 48064  1244  4178 17886 18858 15213 28050   370  3549 28524 23671
 10838  9665 31677 45199 26340 40745 22178 10848 10825 10786 44185 42109
   476  4169   305   419  9342  3564   390 18359 15593  2106  9342  1089
   409   379 16790   304   156  6898  3564  2340 16266  4185 13462    76
  4459   390 40666   225   287   402   390   329 48531 21537   369  1643
 44338 12333  7388  3564    11 41196  1255 50438 24679 17872  3666  4181
  5834 10785 21640   347 17872 29108  3569   220 10842 20151  5024   390
   381   390   297  2465   440 12868   875  6219   165 35358   390  1177
 50779 31114   390   347   388   131  4045 11521  4181 27683  7780  4260
 22179   414 22179 18858    88   378   130 12218 11242   419   390 12177
   371 43255  1220   379 15834    63   421  4456   184   289  5833  2207
   323  2623  6898 43877   363 32733 49029 34709 13430 10181    63    75
 24755 39624 13462   396 15733   523 50422  5674 17877 26001   299   390
 14564  5267  4172   108 19596 11656  4185   135 28915  7780 11211    87
 11278 27194   451  2396   331 31199  2271    76  6415  1547  9245  3666
   130 35358 16790   438   356    76 49214    76   329  7508 13462   184
 17881 10793 16790 10517]
preds: [390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 379 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390 390
 390 390 390 390 390 390 390 390 390 390]
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Epoch [10/100000]
First Position Metrics:
Train Loss: 2.8207
Train Accuracy: 0.0000
Train Precision (micro): 0.0000, Train Precision (macro): 0.0000
Train Recall (micro): 0.0000, Train Recall (macro): 0.0000
Train F1 (micro): 0.0000, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 2.1198
Train Accuracy: 0.0344
Train Precision (micro): 0.0344, Train Precision (macro): 0.0001
Train Recall (micro): 0.0344, Train Recall (macro): 0.0024
Train F1 (micro): 0.0344, Train F1 (macro): 0.0002
  0%|          | 9/100000 [00:19<59:25:32,  2.14s/it]
  0%|          | 19/100000 [01:33<72:42:38,  2.62s/it] 

Epoch [10/100000]
First Position Metrics:
Train Loss: 2.7918
Train Accuracy: 0.0047
Train Precision (micro): 0.0047, Train Precision (macro): 0.0000
Train Recall (micro): 0.0047, Train Recall (macro): 0.0017
Train F1 (micro): 0.0047, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 2.0950
Train Accuracy: 0.0219
Train Precision (micro): 0.0219, Train Precision (macro): 0.0001
Train Recall (micro): 0.0219, Train Recall (macro): 0.0023
Train F1 (micro): 0.0219, Train F1 (macro): 0.0001

First Position Validation Metrics:
Val Loss: 13.9506, Val Accuracy: 0.0028
Val Precision (micro): 0.0028, Val Precision (macro): 0.0000
Val Recall (micro): 0.0028, Val Recall (macro): 0.0004
Val F1 (micro): 0.0028, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 10.4338, Val Accuracy: 0.0219
Val Precision (micro): 0.0219, Val Precision (macro): 0.0000
Val Recall (micro): 0.0219, Val Recall (macro): 0.0008
Val F1 (micro): 0.0219, Val F1 (macro): 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Train Loss: 4.8868, Val Loss: 24.3844
--------------------------------------------------------------------------------
Epoch [20/100000]
First Position Metrics:
Train Loss: 5.6702
Train Accuracy: 0.0125
Train Precision (micro): 0.0125, Train Precision (macro): 0.0000
Train Recall (micro): 0.0125, Train Recall (macro): 0.0017
Train F1 (micro): 0.0125, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 4.2848
Train Accuracy: 0.0266
Train Precision (micro): 0.0266, Train Precision (macro): 0.0001
Train Recall (micro): 0.0266, Train Recall (macro): 0.0024
Train F1 (micro): 0.0266, Train F1 (macro): 0.0001

First Position Validation Metrics:
Val Loss: 13.9076, Val Accuracy: 0.0028
Val Precision (micro): 0.0028, Val Precision (macro): 0.0000
Val Recall (micro): 0.0028, Val Recall (macro): 0.0004
Val F1 (micro): 0.0028, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 10.3079, Val Accuracy: 0.0219
Val Precision (micro): 0.0219, Val Precision (macro): 0.0000
Val Recall (micro): 0.0219, Val Recall (macro): 0.0008
Val F1 (micro): 0.0219, Val F1 (macro): 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Train Loss: 5.0681, Val Loss: 24.2155
--------------------------------------------------------------------------------
Epoch [30/100000]
First Position Metrics:
Train Loss: 8.4457
Train Accuracy: 0.0016
Train Precision (micro): 0.0016, Train Precision (macro): 0.0000
Train Recall (micro): 0.0016, Train Recall (macro): 0.0017
Train F1 (micro): 0.0016, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 6.3373
Train Accuracy: 0.0172
Train Precision (micro): 0.0172, Train Precision (macro): 0.0000
Train Recall (micro): 0.0172, Train Recall (macro): 0.0023
Train F1 (micro): 0.0172, Train F1 (macro): 0.0001

First Position Validation Metrics:
Val Loss: 13.8729, Val Accuracy: 0.0028
Val Precision (micro): 0.0028, Val Precision (macro): 0.0000
Val Recall (micro): 0.0028, Val Recall (macro): 0.0004
Val F1 (micro): 0.0028, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 10.2131, Val Accuracy: 0.0219
Val Precision (micro): 0.0219, Val Precision (macro): 0.0000
Val Recall (micro): 0.0219, Val Recall (macro): 0.0008
Val F1 (micro): 0.0219, Val F1 (macro): 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Train Loss: 4.8280, Val Loss: 24.0860
--------------------------------------------------------------------------------
Epoch [40/100000]
First Position Metrics:
Train Loss: 11.1601
Train Accuracy: 0.0047
Train Precision (micro): 0.0047, Train Precision (macro): 0.0000
Train Recall (micro): 0.0047, Train Recall (macro): 0.0017
Train F1 (micro): 0.0047, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 8.3725
Train Accuracy: 0.0250
Train Precision (micro): 0.0250, Train Precision (macro): 0.0001
Train Recall (micro): 0.0250, Train Recall (macro): 0.0025
Train F1 (micro): 0.0250, Train F1 (macro): 0.0001

First Position Validation Metrics:
Val Loss: 13.8548, Val Accuracy: 0.0028
Val Precision (micro): 0.0028, Val Precision (macro): 0.0000
Val Recall (micro): 0.0028, Val Recall (macro): 0.0004
Val F1 (micro): 0.0028, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 10.1659, Val Accuracy: 0.0219
Val Precision (micro): 0.0219, Val Precision (macro): 0.0000
Val Recall (micro): 0.0219, Val Recall (macro): 0.0008
Val F1 (micro): 0.0219, Val F1 (macro): 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Train Loss: 4.7496, Val Loss: 24.0207
--------------------------------------------------------------------------------
Epoch [50/100000]
First Position Metrics:
Train Loss: 13.8303
Train Accuracy: 0.0031
Train Precision (micro): 0.0031, Train Precision (macro): 0.0000
Train Recall (micro): 0.0031, Train Recall (macro): 0.0017
Train F1 (micro): 0.0031, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 10.3660
Train Accuracy: 0.0250
Train Precision (micro): 0.0250, Train Precision (macro): 0.0001
Train Recall (micro): 0.0250, Train Recall (macro): 0.0024
Train F1 (micro): 0.0250, Train F1 (macro): 0.0001

First Position Validation Metrics:
Val Loss: 13.8506, Val Accuracy: 0.0028
Val Precision (micro): 0.0028, Val Precision (macro): 0.0000
Val Recall (micro): 0.0028, Val Recall (macro): 0.0004
Val F1 (micro): 0.0028, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 10.1550, Val Accuracy: 0.0219
Val Precision (micro): 0.0219, Val Precision (macro): 0.0000
Val Recall (micro): 0.0219, Val Recall (macro): 0.0008
Val F1 (micro): 0.0219, Val F1 (macro): 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Train Loss: 4.6638, Val Loss: 24.0056
--------------------------------------------------------------------------------
Epoch [60/100000]
First Position Metrics:
Train Loss: 16.4921
Train Accuracy: 0.0063
Train Precision (micro): 0.0063, Train Precision (macro): 0.0000
Train Recall (micro): 0.0063, Train Recall (macro): 0.0014
Train F1 (micro): 0.0063, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 12.3490
Train Accuracy: 0.0281
Train Precision (micro): 0.0281, Train Precision (macro): 0.0001
Train Recall (micro): 0.0281, Train Recall (macro): 0.0024
Train F1 (micro): 0.0281, Train F1 (macro): 0.0001

First Position Validation Metrics:
Val Loss: 13.8056, Val Accuracy: 0.0037
Val Precision (micro): 0.0037, Val Precision (macro): 0.0000
Val Recall (micro): 0.0037, Val Recall (macro): 0.0004
Val F1 (micro): 0.0037, Val F1 (macro): 0.0000

End Position Validation Metrics:
Val Loss: 10.0392, Val Accuracy: 0.0219
Val Precision (micro): 0.0219, Val Precision (macro): 0.0000
Val Recall (micro): 0.0219, Val Recall (macro): 0.0008
Val F1 (micro): 0.0219, Val F1 (macro): 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Train Loss: 4.6448, Val Loss: 23.8449
--------------------------------------------------------------------------------
Epoch [70/100000]
First Position Metrics:
Train Loss: 19.1955
Train Accuracy: 0.0000
Train Precision (micro): 0.0000, Train Precision (macro): 0.0000
Train Recall (micro): 0.0000, Train Recall (macro): 0.0000
Train F1 (micro): 0.0000, Train F1 (macro): 0.0000

End Position Metrics:
Train Loss: 14.3275
Train Accuracy: 0.0266
Train Precision (micro): 0.0266, Train Precision (macro): 0.0001
Train Recall (micro): 0.0266, Train Recall (macro): 0.0024
Train F1 (micro): 0.0266, Train F1 (macro): 0.0001
