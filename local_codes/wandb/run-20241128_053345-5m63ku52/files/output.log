{0: 2, 1: 33, 2: 1298, 3: 5633, 4: 3733, 5: 5181, 6: 5444, 7: 15383, 8: 65228, 9: 59006, 10: 53852, 11: 141571, 12: 20369, 13: 13615, 14: 17388, 15: 32162, 16: 35564, 17: 34333, 18: 33100, 19: 43499, 20: 61507, 21: 57902, 22: 31211, 23: 32827, 24: 107510, 25: 82470, 26: 96454, 27: 90631, 28: 85202, 29: 70506, 30: 71899, 31: 26726, 32: 11716, 33: 6444, 34: 2510, 35: 872, 36: 4}

Taxonomic ranks sorted by number of taxa:
11: 141571
24: 107510
26: 96454
27: 90631
28: 85202
25: 82470
30: 71899
29: 70506
8: 65228
20: 61507
9: 59006
21: 57902
10: 53852
19: 43499
16: 35564
17: 34333
18: 33100
23: 32827
15: 32162
22: 31211
31: 26726
12: 20369
14: 17388
7: 15383
13: 13615
32: 11716
33: 6444
3: 5633
6: 5444
5: 5181
4: 3733
34: 2510
2: 1298
35: 872
1: 33
36: 4
0: 2
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable parameters: 754.155969 M
Total parameters: 1406.51247 M
ESM1b(
  (esm): EsmModel(
    (embeddings): EsmEmbeddings(
      (word_embeddings): Embedding(33, 1280, padding_idx=1)
      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (position_embeddings): Embedding(1026, 1280, padding_idx=1)
    )
    (encoder): EsmEncoder(
      (layer): ModuleList(
        (0-32): 33 x EsmLayer(
          (attention): EsmAttention(
            (self): EsmSelfAttention(
              (query): Linear(in_features=1280, out_features=1280, bias=True)
              (key): Linear(in_features=1280, out_features=1280, bias=True)
              (value): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (output): EsmSelfOutput(
              (dense): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
          (intermediate): EsmIntermediate(
            (dense): Linear(in_features=1280, out_features=5120, bias=True)
          )
          (output): EsmOutput(
            (dense): Linear(in_features=5120, out_features=1280, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    )
    (pooler): EsmPooler(
      (dense): Linear(in_features=1280, out_features=1280, bias=True)
      (activation): Tanh()
    )
    (contact_head): EsmContactPredictionHead(
      (regression): Linear(in_features=660, out_features=1, bias=True)
      (activation): Sigmoid()
    )
  )
  (heads): ModuleDict(
    (0): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2, bias=True)
    )
    (1): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33, bias=True)
    )
    (2): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=1298, bias=True)
    )
    (3): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5633, bias=True)
    )
    (4): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=3733, bias=True)
    )
    (5): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5181, bias=True)
    )
    (6): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5444, bias=True)
    )
    (7): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=15383, bias=True)
    )
    (8): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=65228, bias=True)
    )
    (9): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=59006, bias=True)
    )
    (10): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=53852, bias=True)
    )
    (11): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=141571, bias=True)
    )
    (12): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=20369, bias=True)
    )
    (13): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=13615, bias=True)
    )
    (14): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=17388, bias=True)
    )
    (15): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32162, bias=True)
    )
    (16): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=35564, bias=True)
    )
    (17): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=34333, bias=True)
    )
    (18): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33100, bias=True)
    )
    (19): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=43499, bias=True)
    )
    (20): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=61507, bias=True)
    )
    (21): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=57902, bias=True)
    )
    (22): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=31211, bias=True)
    )
    (23): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32827, bias=True)
    )
    (24): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=107510, bias=True)
    )
    (25): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=82470, bias=True)
    )
    (26): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=96454, bias=True)
    )
    (27): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=90631, bias=True)
    )
    (28): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=85202, bias=True)
    )
    (29): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=70506, bias=True)
    )
    (30): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=71899, bias=True)
    )
    (31): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=26726, bias=True)
    )
    (32): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=11716, bias=True)
    )
    (33): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=6444, bias=True)
    )
    (34): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2510, bias=True)
    )
    (35): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=872, bias=True)
    )
    (36): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=4, bias=True)
    )
  )
)
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable parameters: 754.155969 M
Total parameters: 1406.51247 M
ESM1b(
  (esm): EsmModel(
    (embeddings): EsmEmbeddings(
      (word_embeddings): Embedding(33, 1280, padding_idx=1)
      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (position_embeddings): Embedding(1026, 1280, padding_idx=1)
    )
    (encoder): EsmEncoder(
      (layer): ModuleList(
        (0-32): 33 x EsmLayer(
          (attention): EsmAttention(
            (self): EsmSelfAttention(
              (query): Linear(in_features=1280, out_features=1280, bias=True)
              (key): Linear(in_features=1280, out_features=1280, bias=True)
              (value): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (output): EsmSelfOutput(
              (dense): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
          (intermediate): EsmIntermediate(
            (dense): Linear(in_features=1280, out_features=5120, bias=True)
          )
          (output): EsmOutput(
            (dense): Linear(in_features=5120, out_features=1280, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    )
    (pooler): EsmPooler(
      (dense): Linear(in_features=1280, out_features=1280, bias=True)
      (activation): Tanh()
    )
    (contact_head): EsmContactPredictionHead(
      (regression): Linear(in_features=660, out_features=1, bias=True)
      (activation): Sigmoid()
    )
  )
  (heads): ModuleDict(
    (0): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2, bias=True)
    )
    (1): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33, bias=True)
    )
    (2): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=1298, bias=True)
    )
    (3): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5633, bias=True)
    )
    (4): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=3733, bias=True)
    )
    (5): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5181, bias=True)
    )
    (6): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5444, bias=True)
    )
    (7): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=15383, bias=True)
    )
    (8): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=65228, bias=True)
    )
    (9): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=59006, bias=True)
    )
    (10): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=53852, bias=True)
    )
    (11): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=141571, bias=True)
    )
    (12): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=20369, bias=True)
    )
    (13): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=13615, bias=True)
    )
    (14): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=17388, bias=True)
    )
    (15): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32162, bias=True)
    )
    (16): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=35564, bias=True)
    )
    (17): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=34333, bias=True)
    )
    (18): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33100, bias=True)
    )
    (19): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=43499, bias=True)
    )
    (20): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=61507, bias=True)
    )
    (21): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=57902, bias=True)
    )
    (22): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=31211, bias=True)
    )
    (23): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32827, bias=True)
    )
    (24): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=107510, bias=True)
    )
    (25): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=82470, bias=True)
    )
    (26): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=96454, bias=True)
    )
    (27): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=90631, bias=True)
    )
    (28): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=85202, bias=True)
    )
    (29): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=70506, bias=True)
    )
    (30): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=71899, bias=True)
    )
    (31): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=26726, bias=True)
    )
    (32): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=11716, bias=True)
    )
    (33): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=6444, bias=True)
    )
    (34): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2510, bias=True)
    )
    (35): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=872, bias=True)
    )
    (36): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=4, bias=True)
    )
  )
)
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm1b_t33_650M_UR50S and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable parameters: 754.155969 M
Total parameters: 1406.51247 M
ESM1b(
  (esm): EsmModel(
    (embeddings): EsmEmbeddings(
      (word_embeddings): Embedding(33, 1280, padding_idx=1)
      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (position_embeddings): Embedding(1026, 1280, padding_idx=1)
    )
    (encoder): EsmEncoder(
      (layer): ModuleList(
        (0-32): 33 x EsmLayer(
          (attention): EsmAttention(
            (self): EsmSelfAttention(
              (query): Linear(in_features=1280, out_features=1280, bias=True)
              (key): Linear(in_features=1280, out_features=1280, bias=True)
              (value): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (output): EsmSelfOutput(
              (dense): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
          (intermediate): EsmIntermediate(
            (dense): Linear(in_features=1280, out_features=5120, bias=True)
          )
          (output): EsmOutput(
            (dense): Linear(in_features=5120, out_features=1280, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    )
    (pooler): EsmPooler(
      (dense): Linear(in_features=1280, out_features=1280, bias=True)
      (activation): Tanh()
    )
    (contact_head): EsmContactPredictionHead(
      (regression): Linear(in_features=660, out_features=1, bias=True)
      (activation): Sigmoid()
    )
  )
  (heads): ModuleDict(
    (0): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2, bias=True)
    )
    (1): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33, bias=True)
    )
    (2): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=1298, bias=True)
    )
    (3): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5633, bias=True)
    )
    (4): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=3733, bias=True)
    )
    (5): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5181, bias=True)
    )
    (6): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=5444, bias=True)
    )
    (7): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=15383, bias=True)
    )
    (8): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=65228, bias=True)
    )
    (9): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=59006, bias=True)
    )
    (10): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=53852, bias=True)
    )
    (11): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=141571, bias=True)
    )
    (12): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=20369, bias=True)
    )
    (13): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=13615, bias=True)
    )
    (14): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=17388, bias=True)
    )
    (15): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32162, bias=True)
    )
    (16): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=35564, bias=True)
    )
    (17): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=34333, bias=True)
    )
    (18): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=33100, bias=True)
    )
    (19): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=43499, bias=True)
    )
    (20): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=61507, bias=True)
    )
    (21): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=57902, bias=True)
    )
    (22): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=31211, bias=True)
    )
    (23): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32827, bias=True)
    )
    (24): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=107510, bias=True)
    )
    (25): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=82470, bias=True)
    )
    (26): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=96454, bias=True)
    )
    (27): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=90631, bias=True)
    )
    (28): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=85202, bias=True)
    )
    (29): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=70506, bias=True)
    )
    (30): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=71899, bias=True)
    )
    (31): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=26726, bias=True)
    )
    (32): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=11716, bias=True)
    )
    (33): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=6444, bias=True)
    )
    (34): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2510, bias=True)
    )
    (35): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=872, bias=True)
    )
    (36): Sequential(
      (0): Linear(in_features=1280, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=4, bias=True)
    )
  )
)
  0%|          | 0/100000 [00:00<?, ?it/s]
  1%|          | 999/100000 [10:59:27<1089:12:06, 39.61s/it]
Epoch [1000/100000]
Train Loss: 64.8043
Val Loss: 44.6204
{0: 2.6454093750000003, 1: 0.5501584375, 2: 1.2112196874999999, 3: 1.9088046875, 4: 2.362386875, 5: 2.9188134375, 6: 3.5082921874999995, 7: 4.5501528124999995, 8: 5.431806875, 9: 4.292605, 10: 2.4247971875000003, 11: 1.91299, 12: 0.8019737499999999, 13: 0.759174375, 14: 0.761433125, 15: 0.7486503125, 16: 0.6173296875000001, 17: 0.6441049999999999, 18: 0.6635578125, 19: 0.6765375, 20: 0.6629100000000001, 21: 0.6889256250000001, 22: 0.6193015624999999, 23: 0.5004046874999999, 24: 0.43457468749999995, 25: 0.4309890625, 26: 0.34685062499999997, 27: 0.39475750000000004, 28: 0.314919375, 29: 0.3291581250000001, 30: 0.267598125, 31: 0.13869499999999998, 32: 0.09680718750000002, 33: 0.002741875, 34: 0.0012321875, 35: 0.0003409375, 36: 1.03125e-05}
