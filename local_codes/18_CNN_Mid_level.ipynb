{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539e4331-e6e7-40e1-9729-df18d43a6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      " WORLD_SIZE=1 , LOCAL_WORLD_SIZE=1,RANK =0,LOCAL_RANK = 0 \n",
      "../checkpoints/CNN last level_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malirezanor\u001b[0m (\u001b[33malireza_noroozi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aac/Alireza/local_codes/wandb/run-20241124_192800-6gjkjh2f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alireza_noroozi/CNN%20last%20level/runs/6gjkjh2f' target=\"_blank\">sandy-cloud-11</a></strong> to <a href='https://wandb.ai/alireza_noroozi/CNN%20last%20level' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alireza_noroozi/CNN%20last%20level' target=\"_blank\">https://wandb.ai/alireza_noroozi/CNN%20last%20level</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alireza_noroozi/CNN%20last%20level/runs/6gjkjh2f' target=\"_blank\">https://wandb.ai/alireza_noroozi/CNN%20last%20level/runs/6gjkjh2f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alireza_noroozi/CNN%20last%20level/runs/6gjkjh2f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8fbb531bd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys, os, math\n",
    "import wandb\n",
    "\n",
    "sys.path.insert(0, '../dlp')\n",
    "from batch import Batch\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "epochs = 100_000\n",
    "val_epoch = 1000\n",
    "num_val = 500\n",
    "batch_size = 64\n",
    "dataset_name = \"corpus_200_500_random\"\n",
    "lr = 0.01\n",
    "model_name = \"CNN last level\"\n",
    "max_seq_len = 500\n",
    "\n",
    "from data_access import PQDataAccess\n",
    "da = PQDataAccess(f\"/home/aac/Alireza/datasets/export_pqt_4_taxseq_new/{dataset_name}\", batch_size)\n",
    "\n",
    "checkpoint_dir = f\"../checkpoints/{model_name}_checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "print(checkpoint_dir)\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=model_name,\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Cnn last level\",\n",
    "        \"dataset\": dataset_name,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_szie\": batch_size,\n",
    "        \"max_seq_len\": max_seq_len\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6fe57f-9524-4401-b0d2-172d34368e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dictionary.\n",
      "first level # of Classes 1276825\n"
     ]
    }
   ],
   "source": [
    "from data_process import normal_CNN_batch\n",
    "df = pd.read_csv('../data/new_output_id.csv')\n",
    "\n",
    "first_unique_labels = sorted(set(df['Organism_ID'].values))\n",
    "first_label_to_idx = {label: idx for idx, label in enumerate(first_unique_labels)}\n",
    "first_idx_to_label = {idx: label for label, idx in first_label_to_idx.items()}\n",
    "first_map_label = {r['Organism_ID']: first_label_to_idx[r['Organism_ID']] for _, r in df.iterrows()}\n",
    "\n",
    "print(\"first level # of Classes\", len(first_unique_labels))\n",
    "first_num_classes = len(first_unique_labels)\n",
    "\n",
    "\n",
    "# end_unique_labels = sorted(set(df['new label'].values))\n",
    "# end_label_to_idx = {label: idx for idx, label in enumerate(end_unique_labels)}\n",
    "# end_idx_to_label = {idx: label for label, idx in end_label_to_idx.items()}\n",
    "# end_map_label = {r['Organism_ID']: end_label_to_idx[r['new label']] for _, r in df.iterrows()}\n",
    "\n",
    "# print(\"end level # of Classes\", len(end_unique_labels))\n",
    "# end_num_classes = len(end_unique_labels)\n",
    "\n",
    "\n",
    "def batch_convertor(b):\n",
    "    inputs = normal_CNN_batch(b)\n",
    "    \n",
    "    first_tax_ids = [first_map_label[e['Taxonomic_lineage_IDs']] for e in b]\n",
    "    # end_tax_ids = [end_map_label[e['Taxonomic_lineage_IDs']] for e in b]\n",
    "\n",
    "    tax_ids = {\n",
    "        \"first\": torch.LongTensor(first_tax_ids),\n",
    "        # \"end\": torch.LongTensor(end_tax_ids),\n",
    "    }\n",
    "    \n",
    "    return Batch(inputs, tax_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7966c083-c292-40e1-8172-15d78cc6d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, bottleneck_factor=0.5):\n",
    "        super().__init__()\n",
    "        bottleneck_channels = int(channels * bottleneck_factor)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            # Add operation (residual connection is added later)\n",
    "            nn.Conv1d(channels, bottleneck_channels, kernel_size=1),  # bottleneck convolution\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(bottleneck_channels),\n",
    "            nn.Conv1d(bottleneck_channels, bottleneck_channels, kernel_size=21, padding='same'),  # dilated convolution\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(bottleneck_channels),\n",
    "            nn.Conv1d(bottleneck_channels, channels, kernel_size=1),  # restore channels\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.layers(x)  # residual connection\n",
    "\n",
    "class EnhancedProteinCNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes_first,\n",
    "                 num_classes_end,\n",
    "                 vocab_size=25,\n",
    "                 embedding_dim=128,\n",
    "                 max_seq_length=max_seq_len,\n",
    "                 num_filters=2000,  # as per parameter table\n",
    "                 dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Original embedding for amino acid indices\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Additional feature processing\n",
    "        self.feature_dense = nn.Linear(3, embedding_dim)\n",
    "        \n",
    "        # Process global sequence features\n",
    "        self.global_feature_dense = nn.Linear(28, embedding_dim)\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, num_filters, kernel_size=21, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_filters)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks (multiple blocks as shown in the architecture)\n",
    "        self.residual_blocks = nn.ModuleList([\n",
    "            ResidualBlock(num_filters) for _ in range(5)  # adjust number of blocks as needed\n",
    "        ])\n",
    "        \n",
    "        # Max pooling\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(num_filters + embedding_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes_first)\n",
    "        # self.fc4 = nn.Linear(256, num_classes_end)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "    \n",
    "    def forward(self, x, global_features, attention_mask=None):\n",
    "        # Process amino acid indices\n",
    "        seq_embeddings = self.embedding(x[:, :, 0].long())\n",
    "        \n",
    "        # Process additional features\n",
    "        feature_embeddings = self.feature_dense(x[:, :, 1:4])\n",
    "        \n",
    "        # Combine embeddings\n",
    "        x = seq_embeddings + feature_embeddings\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        # Process global sequence features\n",
    "        global_embedding = self.global_feature_dense(global_features)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            x = x * attention_mask.unsqueeze(-1)\n",
    "        \n",
    "        # Transpose for convolution\n",
    "        x = x.transpose(1, 2)  # Shape: (batch_size, embedding_dim, seq_length)\n",
    "        \n",
    "        # Initial convolution\n",
    "        x = self.initial_conv(x)\n",
    "        \n",
    "        # Apply residual blocks\n",
    "        for block in self.residual_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        \n",
    "        # Add global features\n",
    "        x = torch.cat([x, global_embedding], dim=1)\n",
    "        \n",
    "        # Final fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        # end_x = self.fc4(x)\n",
    "        first_x = self.fc3(x)\n",
    "        \n",
    "        # return first_x, end_x\n",
    "        return first_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1215f3ed-a162-4fce-a9d5-6777755c6d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 459.795081 M parameters\n",
      "EnhancedProteinCNN(\n",
      "  (embedding): Embedding(25, 128, padding_idx=0)\n",
      "  (feature_dense): Linear(in_features=3, out_features=128, bias=True)\n",
      "  (global_feature_dense): Linear(in_features=28, out_features=128, bias=True)\n",
      "  (initial_conv): Sequential(\n",
      "    (0): Conv1d(128, 2000, kernel_size=(21,), stride=(1,), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (residual_blocks): ModuleList(\n",
      "    (0-4): 5 x ResidualBlock(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv1d(2000, 1000, kernel_size=(1,), stride=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Conv1d(1000, 1000, kernel_size=(21,), stride=(1,), padding=same)\n",
      "        (4): ReLU()\n",
      "        (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Conv1d(1000, 2000, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=2128, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1276825, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "end_num_classes = 51275\n",
    "model = EnhancedProteinCNN(first_num_classes, end_num_classes).to(device)\n",
    "print(\"model:\", sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Cosine annealing with warm restarts\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,  # Initial restart interval\n",
    "    T_mult=2,  # Multiply interval by 2 after each restart\n",
    "    eta_min=1e-6  # Minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ddd0ac-8e02-4c3f-898b-1ed2e3bbb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def compute_metrics(all_labels, all_preds, running_loss, num_val):\n",
    "    # Convert tensors to numpy arrays\n",
    "    labels_np = torch.cat(all_labels).numpy()\n",
    "    preds_np = torch.cat(all_preds).numpy()\n",
    "\n",
    "    # print(\"labels:\", labels_np)\n",
    "    # print(\"preds:\", preds_np)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(labels_np, preds_np)\n",
    "    \n",
    "    # Precision scores\n",
    "    precision_macro = precision_score(labels_np, preds_np, average='macro')\n",
    "    precision_micro = precision_score(labels_np, preds_np, average='micro')\n",
    "    \n",
    "    # Recall scores\n",
    "    recall_macro = recall_score(labels_np, preds_np, average='macro')\n",
    "    recall_micro = recall_score(labels_np, preds_np, average='micro')\n",
    "    \n",
    "    # F1 scores\n",
    "    f1_macro = f1_score(labels_np, preds_np, average='macro')\n",
    "    f1_micro = f1_score(labels_np, preds_np, average='micro')\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = running_loss / num_val\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa1ebd7-371b-46d6-9538-c45f2fbba45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = [da.get_batch() for _ in range(num_val)]\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    first_running_loss = 0.0\n",
    "    # end_running_loss = 0.0\n",
    "    first_all_preds = []\n",
    "    first_all_labels = []\n",
    "\n",
    "    # end_all_preds = []\n",
    "    # end_all_labels = []\n",
    "    \n",
    "    for epoch in range(num_val):\n",
    "        with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "            tensor_batch = batch_convertor(val_batches[epoch])\n",
    "            tensor_batch.gpu(device)\n",
    "        \n",
    "            first_labels = tensor_batch.taxes[\"first\"]\n",
    "            # end_labels = tensor_batch.taxes[\"end\"]\n",
    "            \n",
    "            outputs = model(\n",
    "                tensor_batch.seq_ids[\"batch_encoding\"],\n",
    "                tensor_batch.seq_ids[\"batch_global_features\"],\n",
    "                tensor_batch.seq_ids[\"batch_maks\"],\n",
    "            )\n",
    "\n",
    "            first_loss = criterion(outputs, first_labels)\n",
    "            # end_loss = criterion(outputs[1], end_labels)\n",
    "            # Calculate the loss\n",
    "            # loss = first_loss + end_loss\n",
    "            loss = first_loss\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            first_running_loss += first_loss.item()\n",
    "            # end_running_loss += end_loss.item()\n",
    "                \n",
    "            first_preds = torch.argmax(outputs, dim=1)\n",
    "            # end_preds = torch.argmax(outputs[1], dim=1)\n",
    "    \n",
    "            first_all_preds.append(first_preds.cpu())\n",
    "            first_all_labels.append(first_labels.cpu())\n",
    "\n",
    "            # end_all_preds.append(end_preds.cpu())\n",
    "            # end_all_labels.append(end_labels.cpu())\n",
    "\n",
    "    return {\n",
    "        \"first\": compute_metrics(first_all_labels, first_all_preds, first_running_loss, num_val),\n",
    "        # \"end\": compute_metrics(end_all_labels, end_all_preds, end_running_loss, num_val),\n",
    "        \"loss\": running_loss / num_val\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22794934-d147-4deb-b1ab-631d0edb16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def load_checkpoint(model, optimizer=None, scheduler=None):\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pt'))        \n",
    "    # Extract epoch numbers and find latest\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "    \n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Load optimizer state if provided (for training)\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        # Move optimizer state to GPU if necessary\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(device)\n",
    "\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Get training metadata\n",
    "    epoch = checkpoint['epoch']\n",
    "    metrics = checkpoint['metrics']\n",
    "    \n",
    "    print(f\"Successfully loaded checkpoint from epoch {epoch}\")\n",
    "    print(\"Metrics at checkpoint:\", metrics)\n",
    "    \n",
    "    return model, optimizer, scheduler, epoch, metrics\n",
    "        \n",
    "# model, optimizer, scheduler, latest_epoch, metrics = load_checkpoint(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0eaa816-92f0-4251-9de2-6ed3748a2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 999/100000 [31:22<51:53:31,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 32.0788, Train Accuracy: 0.0046\n",
      "Train Precision (micro): 0.0046, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0046, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0046, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 11.2562, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1999/100000 [1:09:26<51:45:37,  1.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 54.5968, Train Accuracy: 0.0051\n",
      "Train Precision (micro): 0.0051, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0051, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0051, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 11.1065, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2999/100000 [1:47:32<50:35:34,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 76.6682, Train Accuracy: 0.0052\n",
      "Train Precision (micro): 0.0052, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0052, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0052, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.9646, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3999/100000 [2:25:35<51:09:45,  1.92s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 98.5535, Train Accuracy: 0.0047\n",
      "Train Precision (micro): 0.0047, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0047, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0047, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.7333, Val Accuracy: 0.0040\n",
      "Val Precision (micro): 0.0040, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0040, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0040, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4999/100000 [3:03:42<49:21:09,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 120.1199, Train Accuracy: 0.0047\n",
      "Train Precision (micro): 0.0047, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0047, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0047, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.6502, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5999/100000 [3:41:52<49:02:34,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 141.4306, Train Accuracy: 0.0048\n",
      "Train Precision (micro): 0.0048, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0048, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0048, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.6493, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6999/100000 [4:19:59<48:53:19,  1.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 164.5604, Train Accuracy: 0.0045\n",
      "Train Precision (micro): 0.0045, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0045, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0045, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.5071, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7999/100000 [4:58:03<47:55:21,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 187.6277, Train Accuracy: 0.0052\n",
      "Train Precision (micro): 0.0052, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0052, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0052, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.4212, Val Accuracy: 0.0047\n",
      "Val Precision (micro): 0.0047, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0047, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0047, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 8999/100000 [5:36:05<47:22:41,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 210.1652, Train Accuracy: 0.0054\n",
      "Train Precision (micro): 0.0054, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0054, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0054, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.3768, Val Accuracy: 0.0040\n",
      "Val Precision (micro): 0.0040, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0040, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0040, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9999/100000 [6:14:12<47:18:42,  1.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 231.0216, Train Accuracy: 0.0043\n",
      "Train Precision (micro): 0.0043, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0043, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0043, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.3609, Val Accuracy: 0.0040\n",
      "Val Precision (micro): 0.0040, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0040, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0040, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10999/100000 [6:52:20<46:22:29,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 251.7518, Train Accuracy: 0.0042\n",
      "Train Precision (micro): 0.0042, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0042, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0042, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.3603, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 11999/100000 [7:30:25<45:35:47,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 272.4656, Train Accuracy: 0.0049\n",
      "Train Precision (micro): 0.0049, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0049, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0049, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.2869, Val Accuracy: 0.0047\n",
      "Val Precision (micro): 0.0047, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0047, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0047, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12999/100000 [8:08:30<45:35:51,  1.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 293.0500, Train Accuracy: 0.0053\n",
      "Train Precision (micro): 0.0053, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0053, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0053, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.2364, Val Accuracy: 0.0047\n",
      "Val Precision (micro): 0.0047, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0047, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0047, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 13999/100000 [8:46:32<44:55:33,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 313.4993, Train Accuracy: 0.0051\n",
      "Train Precision (micro): 0.0051, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0051, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0051, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1991, Val Accuracy: 0.0046\n",
      "Val Precision (micro): 0.0046, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0046, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0046, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14999/100000 [9:24:40<44:25:28,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 333.9409, Train Accuracy: 0.0047\n",
      "Train Precision (micro): 0.0047, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0047, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0047, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1719, Val Accuracy: 0.0040\n",
      "Val Precision (micro): 0.0040, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0040, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0040, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 15999/100000 [10:02:45<44:23:09,  1.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 354.3143, Train Accuracy: 0.0049\n",
      "Train Precision (micro): 0.0049, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0049, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0049, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1540, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 16999/100000 [10:40:47<43:01:19,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 374.5937, Train Accuracy: 0.0050\n",
      "Train Precision (micro): 0.0050, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0050, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0050, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1410, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 17999/100000 [11:18:53<42:31:44,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 394.8905, Train Accuracy: 0.0053\n",
      "Train Precision (micro): 0.0053, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0053, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0053, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1327, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 18999/100000 [11:56:55<42:04:28,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 415.1665, Train Accuracy: 0.0050\n",
      "Train Precision (micro): 0.0050, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0050, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0050, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1281, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 19999/100000 [12:35:03<41:44:50,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 435.4311, Train Accuracy: 0.0050\n",
      "Train Precision (micro): 0.0050, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0050, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0050, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1262, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 20999/100000 [13:13:10<40:52:53,  1.86s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 455.6756, Train Accuracy: 0.0049\n",
      "Train Precision (micro): 0.0049, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0049, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0049, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1260, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 21999/100000 [13:51:18<40:51:03,  1.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 475.9676, Train Accuracy: 0.0048\n",
      "Train Precision (micro): 0.0048, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0048, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0048, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1238, Val Accuracy: 0.0040\n",
      "Val Precision (micro): 0.0040, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0040, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0040, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 22999/100000 [14:29:25<39:55:34,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 496.2106, Train Accuracy: 0.0045\n",
      "Train Precision (micro): 0.0045, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0045, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0045, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1192, Val Accuracy: 0.0039\n",
      "Val Precision (micro): 0.0039, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0039, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0039, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 23999/100000 [15:07:32<40:08:38,  1.90s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 516.4778, Train Accuracy: 0.0053\n",
      "Train Precision (micro): 0.0053, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0053, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0053, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1127, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 24999/100000 [15:45:38<39:06:51,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 536.7438, Train Accuracy: 0.0046\n",
      "Train Precision (micro): 0.0046, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0046, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0046, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1077, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 25999/100000 [16:23:47<38:17:14,  1.86s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 558.4477, Train Accuracy: 0.0047\n",
      "Train Precision (micro): 0.0047, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0047, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0047, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1023, Val Accuracy: 0.0040\n",
      "Val Precision (micro): 0.0040, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0040, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0040, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 26999/100000 [17:01:53<38:21:07,  1.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 578.6732, Train Accuracy: 0.0053\n",
      "Train Precision (micro): 0.0053, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0053, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0053, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.1001, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 27999/100000 [17:39:57<37:24:43,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 598.8594, Train Accuracy: 0.0057\n",
      "Train Precision (micro): 0.0057, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0057, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0057, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.0976, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 28999/100000 [18:18:03<37:25:02,  1.90s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 619.0754, Train Accuracy: 0.0052\n",
      "Train Precision (micro): 0.0052, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0052, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0052, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.0953, Val Accuracy: 0.0046\n",
      "Val Precision (micro): 0.0046, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0046, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0046, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 29999/100000 [18:56:05<36:31:13,  1.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30000/100000]\n",
      "First Position Metrics:\n",
      "Train Loss: 639.3178, Train Accuracy: 0.0047\n",
      "Train Precision (micro): 0.0047, Train Precision (macro): 0.0000\n",
      "Train Recall (micro): 0.0047, Train Recall (macro): 0.0000\n",
      "Train F1 (micro): 0.0047, Train F1 (macro): 0.0000\n",
      "\n",
      "First Position Validation Metrics:\n",
      "Val Loss: 10.0904, Val Accuracy: 0.0053\n",
      "Val Precision (micro): 0.0053, Val Precision (macro): 0.0000\n",
      "Val Recall (micro): 0.0053, Val Recall (macro): 0.0001\n",
      "Val F1 (micro): 0.0053, Val F1 (macro): 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 30999/100000 [19:38:50<43:44:00,  2.28s/it]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 56\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m val_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m: compute_metrics(first_all_labels, first_all_preds, first_running_loss, num_val),\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# \"end\": compute_metrics(end_all_labels, end_all_preds, end_running_loss, num_val),\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: running_loss \u001b[38;5;241m/\u001b[39m num_val\n\u001b[1;32m     55\u001b[0m     }\n\u001b[0;32m---> 56\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Training metrics - First\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# end_loss = criterion(outputs[1], end_labels)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# loss = first_loss + end_loss\u001b[39;00m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m first_loss\n\u001b[0;32m---> 35\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m first_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m first_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# end_running_loss += end_loss.item()\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "first_running_loss = 0.0\n",
    "# end_running_loss = 0.0\n",
    "\n",
    "first_all_preds = []\n",
    "first_all_labels = []\n",
    "# end_all_preds = []\n",
    "# end_all_labels = []\n",
    "\n",
    "current_lr = lr\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    tensor_batch = batch_convertor(da.get_batch())\n",
    "    tensor_batch.gpu(device)\n",
    "        \n",
    "    first_labels = tensor_batch.taxes[\"first\"]\n",
    "    # end_labels = tensor_batch.taxes[\"end\"]\n",
    "    \n",
    "    outputs = model(\n",
    "        tensor_batch.seq_ids[\"batch_encoding\"],\n",
    "        tensor_batch.seq_ids[\"batch_global_features\"],\n",
    "        tensor_batch.seq_ids[\"batch_maks\"],\n",
    "    )\n",
    "    \n",
    "    first_loss = criterion(outputs, first_labels)\n",
    "    # end_loss = criterion(outputs[1], end_labels)\n",
    "    # Calculate the loss\n",
    "    # loss = first_loss + end_loss\n",
    "    loss = first_loss\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    first_running_loss += first_loss.item()\n",
    "    # end_running_loss += end_loss.item()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    first_preds = torch.argmax(outputs, dim=1)\n",
    "    # end_preds = torch.argmax(outputs[1], dim=1)\n",
    "\n",
    "    first_all_preds.append(first_preds.cpu())\n",
    "    first_all_labels.append(first_labels.cpu())\n",
    "\n",
    "    # end_all_preds.append(end_preds.cpu())\n",
    "    # end_all_labels.append(end_labels.cpu())\n",
    "    \n",
    "    if (epoch + 1) % val_epoch == 0:\n",
    "        train_metrics = {\n",
    "            \"first\": compute_metrics(first_all_labels, first_all_preds, first_running_loss, num_val),\n",
    "            # \"end\": compute_metrics(end_all_labels, end_all_preds, end_running_loss, num_val),\n",
    "            \"loss\": running_loss / num_val\n",
    "        }\n",
    "        val_metrics = evaluate(model)\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "        # Training metrics - First\n",
    "        print(\"First Position Metrics:\")\n",
    "        print(f\"Train Loss: {train_metrics['first']['loss']:.4f}, Train Accuracy: {train_metrics['first']['accuracy']:.4f}\")\n",
    "        print(f\"Train Precision (micro): {train_metrics['first']['precision_micro']:.4f}, Train Precision (macro): {train_metrics['first']['precision_macro']:.4f}\")\n",
    "        print(f\"Train Recall (micro): {train_metrics['first']['recall_micro']:.4f}, Train Recall (macro): {train_metrics['first']['recall_macro']:.4f}\")\n",
    "        print(f\"Train F1 (micro): {train_metrics['first']['f1_micro']:.4f}, Train F1 (macro): {train_metrics['first']['f1_macro']:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Training metrics - End\n",
    "        # print(\"End Position Metrics:\")\n",
    "        # print(f\"Train Loss: {train_metrics['end']['loss']:.4f}\")\n",
    "        # print(f\"Train Accuracy: {train_metrics['end']['accuracy']:.4f}\")\n",
    "        # print(f\"Train Precision (micro): {train_metrics['end']['precision_micro']:.4f}, Train Precision (macro): {train_metrics['end']['precision_macro']:.4f}\")\n",
    "        # print(f\"Train Recall (micro): {train_metrics['end']['recall_micro']:.4f}, Train Recall (macro): {train_metrics['end']['recall_macro']:.4f}\")\n",
    "        # print(f\"Train F1 (micro): {train_metrics['end']['f1_micro']:.4f}, Train F1 (macro): {train_metrics['end']['f1_macro']:.4f}\")\n",
    "        # print()\n",
    "        \n",
    "        # Validation metrics - First\n",
    "        print(\"First Position Validation Metrics:\")\n",
    "        print(f\"Val Loss: {val_metrics['first']['loss']:.4f}, Val Accuracy: {val_metrics['first']['accuracy']:.4f}\")\n",
    "        print(f\"Val Precision (micro): {val_metrics['first']['precision_micro']:.4f}, Val Precision (macro): {val_metrics['first']['precision_macro']:.4f}\")\n",
    "        print(f\"Val Recall (micro): {val_metrics['first']['recall_micro']:.4f}, Val Recall (macro): {val_metrics['first']['recall_macro']:.4f}\")\n",
    "        print(f\"Val F1 (micro): {val_metrics['first']['f1_micro']:.4f}, Val F1 (macro): {val_metrics['first']['f1_macro']:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Validation metrics - End\n",
    "        # print(\"End Position Validation Metrics:\")\n",
    "        # print(f\"Val Loss: {val_metrics['end']['loss']:.4f}, Val Accuracy: {val_metrics['end']['accuracy']:.4f}\")\n",
    "        # print(f\"Val Precision (micro): {val_metrics['end']['precision_micro']:.4f}, Val Precision (macro): {val_metrics['end']['precision_macro']:.4f}\")\n",
    "        # print(f\"Val Recall (micro): {val_metrics['end']['recall_micro']:.4f}, Val Recall (macro): {val_metrics['end']['recall_macro']:.4f}\")\n",
    "        # print(f\"Val F1 (micro): {val_metrics['end']['f1_micro']:.4f}, Val F1 (macro): {val_metrics['end']['f1_macro']:.4f}\")\n",
    "        print(\"+\" * 80)  # Separator\n",
    "        print(f\"Train Loss: {train_metrics['loss']:.4f}, Val Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(\"-\" * 80)  # Separator\n",
    "        \n",
    "\n",
    "        metrics = {\n",
    "            # Training metrics - First\n",
    "            \"train_loss_first\": train_metrics['first']['loss'],\n",
    "            \"train_accuracy_first\": train_metrics['first']['accuracy'],\n",
    "            \"train_precision_micro_first\": train_metrics['first']['precision_micro'],\n",
    "            \"train_precision_macro_first\": train_metrics['first']['precision_macro'],\n",
    "            \"train_recall_micro_first\": train_metrics['first']['recall_micro'],\n",
    "            \"train_recall_macro_first\": train_metrics['first']['recall_macro'],\n",
    "            \"train_f1_micro_first\": train_metrics['first']['f1_micro'],\n",
    "            \"train_f1_macro_first\": train_metrics['first']['f1_macro'],\n",
    "            \n",
    "            # Training metrics - End\n",
    "            # \"train_loss_end\": train_metrics['end']['loss'],\n",
    "            # \"train_accuracy_end\": train_metrics['end']['accuracy'],\n",
    "            # \"train_precision_micro_end\": train_metrics['end']['precision_micro'],\n",
    "            # \"train_precision_macro_end\": train_metrics['end']['precision_macro'],\n",
    "            # \"train_recall_micro_end\": train_metrics['end']['recall_micro'],\n",
    "            # \"train_recall_macro_end\": train_metrics['end']['recall_macro'],\n",
    "            # \"train_f1_micro_end\": train_metrics['end']['f1_micro'],\n",
    "            # \"train_f1_macro_end\": train_metrics['end']['f1_macro'],\n",
    "            \n",
    "            # Validation metrics - First\n",
    "            \"val_loss_first\": val_metrics['first']['loss'],\n",
    "            \"val_accuracy_first\": val_metrics['first']['accuracy'],\n",
    "            \"val_precision_micro_first\": val_metrics['first']['precision_micro'],\n",
    "            \"val_precision_macro_first\": val_metrics['first']['precision_macro'],\n",
    "            \"val_recall_micro_first\": val_metrics['first']['recall_micro'],\n",
    "            \"val_recall_macro_first\": val_metrics['first']['recall_macro'],\n",
    "            \"val_f1_micro_first\": val_metrics['first']['f1_micro'],\n",
    "            \"val_f1_macro_first\": val_metrics['first']['f1_macro'],\n",
    "            \n",
    "            # Validation metrics - End\n",
    "            # \"val_loss_end\": val_metrics['end']['loss'],\n",
    "            # \"val_accuracy_end\": val_metrics['end']['accuracy'],\n",
    "            # \"val_precision_micro_end\": val_metrics['end']['precision_micro'],\n",
    "            # \"val_precision_macro_end\": val_metrics['end']['precision_macro'],\n",
    "            # \"val_recall_micro_end\": val_metrics['end']['recall_micro'],\n",
    "            # \"val_recall_macro_end\": val_metrics['end']['recall_macro'],\n",
    "            # \"val_f1_micro_end\": val_metrics['end']['f1_micro'],\n",
    "            # \"val_f1_macro_end\": val_metrics['end']['f1_macro'],\n",
    "            \n",
    "            # Additional info\n",
    "            \"train_loss\": train_metrics[\"loss\"],\n",
    "            \"val_loss\": val_metrics[\"loss\"],\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"lr\": current_lr,\n",
    "        }\n",
    "        # Step the scheduler\n",
    "        scheduler.step(epoch + loss.item())\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Save periodic checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log(metrics)\n",
    "        \n",
    "        # Reset training metrics\n",
    "        running_loss = 0\n",
    "        first_running_loss = 0\n",
    "        first_all_preds = []\n",
    "        first_all_labels = []\n",
    "        # end_all_preds = []\n",
    "        # end_all_labels = []\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5266ec-7e66-460b-b433-3676bae2d7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721c1f1-34b0-41a0-bf73-8ba38bd69f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
