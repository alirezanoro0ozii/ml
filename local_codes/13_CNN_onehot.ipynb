{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30d535f-696b-4a8a-bf9c-db9e467e0c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dictionary.\n",
      "cuda:1\n",
      " WORLD_SIZE=1 , LOCAL_WORLD_SIZE=1,RANK =0,LOCAL_RANK = 0 \n",
      "../checkpoints/Pure CNN_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malirezanor\u001b[0m (\u001b[33malirezanor-310-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aac/Alireza/local_codes/wandb/run-20241115_143355-yjtsuptu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alirezanor-310-ai/Pure%20CNN/runs/yjtsuptu' target=\"_blank\">soft-sponge-7</a></strong> to <a href='https://wandb.ai/alirezanor-310-ai/Pure%20CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alirezanor-310-ai/Pure%20CNN' target=\"_blank\">https://wandb.ai/alirezanor-310-ai/Pure%20CNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alirezanor-310-ai/Pure%20CNN/runs/yjtsuptu' target=\"_blank\">https://wandb.ai/alirezanor-310-ai/Pure%20CNN/runs/yjtsuptu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alirezanor-310-ai/Pure%20CNN/runs/yjtsuptu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x798014a95510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys, os, math\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "sys.path.insert(0, '../dlp')\n",
    "from data_process import CNN_prepare_batch\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "epochs = 100_000\n",
    "val_epoch = 5000\n",
    "num_val = 500\n",
    "batch_size = 64\n",
    "dataset_name = \"corpus_200_500_random\"\n",
    "virus_dataset_name = \"corpus_200_500_Viruses_random\"\n",
    "non_virus_dataset_name = \"corpus_200_500_Non_Viruses_random\"\n",
    "lr = 0.001\n",
    "model_name = \"Pure CNN\"\n",
    "max_seq_len = 500\n",
    "\n",
    "from data_access import PQDataAccess\n",
    "virus_da = PQDataAccess(f\"/home/aac/Alireza/datasets/export_pqt_4_taxseq/{virus_dataset_name}\", batch_size)\n",
    "non_virus_da = PQDataAccess(f\"/home/aac/Alireza/datasets/export_pqt_4_taxseq/{non_virus_dataset_name}\", batch_size)\n",
    "da = PQDataAccess(f\"/home/aac/Alireza/datasets/export_pqt_4_taxseq/{dataset_name}\", batch_size)\n",
    "\n",
    "checkpoint_dir = f\"../checkpoints/{model_name}_checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "print(checkpoint_dir)\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=model_name,\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Onehot_CNN\",\n",
    "        \"dataset\": dataset_name,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_szie\": batch_size,\n",
    "        \"max_seq_len\": max_seq_len\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7966c083-c292-40e1-8172-15d78cc6d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedProteinCNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes=4,\n",
    "                 vocab_size=25,\n",
    "                 embedding_dim=128,\n",
    "                 max_seq_length=max_seq_len,\n",
    "                 num_filters=256,\n",
    "                 kernel_sizes=[3, 5, 7, 9, 11],\n",
    "                 dropout_rate=0.5):\n",
    "        super(EnhancedProteinCNN, self).__init__()\n",
    "        \n",
    "        # Original embedding for amino acid indices\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Additional feature processing\n",
    "        self.feature_dense = nn.Linear(3, embedding_dim)  # For hydrophobicity, volume, polarity\n",
    "        \n",
    "        # Process global sequence features\n",
    "        self.global_feature_dense = nn.Linear(28, embedding_dim)\n",
    "        \n",
    "        # Convolution layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim,\n",
    "                     out_channels=num_filters,\n",
    "                     kernel_size=k,\n",
    "                     padding='same')\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "        \n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(num_filters)\n",
    "            for _ in kernel_sizes\n",
    "        ])\n",
    "        \n",
    "        # Calculate total features\n",
    "        total_filters = num_filters * len(kernel_sizes) + embedding_dim  # Added embedding_dim for global features\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(total_filters, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "    \n",
    "    def forward(self, x, global_features, attention_mask=None):\n",
    "        # Process amino acid indices\n",
    "        seq_embeddings = self.embedding(x[:, :, 0].long())  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "        \n",
    "        # Process additional features (hydrophobicity, volume, polarity)\n",
    "        feature_embeddings = self.feature_dense(x[:, :, 1:4])  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        x = seq_embeddings + feature_embeddings\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        # Process global sequence features\n",
    "        global_embedding = self.global_feature_dense(global_features)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            x = x * attention_mask.unsqueeze(-1)\n",
    "        \n",
    "        # Transpose for convolution\n",
    "        x = x.transpose(1, 2)  # Shape: (batch_size, embedding_dim, seq_length)\n",
    "        \n",
    "        # Apply convolutions\n",
    "        conv_outputs = []\n",
    "        for conv, bn in zip(self.convs, self.batch_norms):\n",
    "            conv_out = conv(x)\n",
    "            conv_out = bn(conv_out)\n",
    "            conv_out = F.relu(conv_out)\n",
    "            pooled = F.adaptive_max_pool1d(conv_out, 1).squeeze(-1)\n",
    "            conv_outputs.append(pooled)\n",
    "        \n",
    "        # Concatenate all outputs including global features\n",
    "        x = torch.cat(conv_outputs + [global_embedding], dim=1)\n",
    "        \n",
    "        # Final fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1215f3ed-a162-4fce-a9d5-6777755c6d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 2.012164 M parameters\n",
      "EnhancedProteinCNN(\n",
      "  (embedding): Embedding(25, 128, padding_idx=0)\n",
      "  (feature_dense): Linear(in_features=3, out_features=128, bias=True)\n",
      "  (global_feature_dense): Linear(in_features=28, out_features=128, bias=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (1): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=same)\n",
      "    (2): Conv1d(128, 256, kernel_size=(7,), stride=(1,), padding=same)\n",
      "    (3): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (4): Conv1d(128, 256, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  )\n",
      "  (batch_norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1408, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = EnhancedProteinCNN().to(device)\n",
    "print(\"model:\", sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Cosine annealing with warm restarts\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,  # Initial restart interval\n",
    "    T_mult=2,  # Multiply interval by 2 after each restart\n",
    "    eta_min=1e-6  # Minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa1ebd7-371b-46d6-9538-c45f2fbba45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = [da.get_batch() for _ in range(num_val)]\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for epoch in range(num_val):\n",
    "        with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "            tensor_batch = CNN_prepare_batch(val_batches[epoch], max_seq_len_=max_seq_len)\n",
    "            tensor_batch.gpu(device)\n",
    "        \n",
    "            labels = tensor_batch.taxes[\"begining root\"]\n",
    "            outputs = model(\n",
    "                tensor_batch.seq_ids[\"batch_encoding\"],\n",
    "                tensor_batch.seq_ids[\"batch_global_features\"],\n",
    "                tensor_batch.seq_ids[\"batch_maks\"],\n",
    "            )\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "                \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    # Concatenate all batches into single tensors\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Compute evaluation metrics (example: accuracy, F1 score)\n",
    "    accuracy = accuracy_score(all_labels.numpy(), all_preds.numpy())\n",
    "    f1_macro = f1_score(all_labels.numpy(), all_preds.numpy(), average='macro')  # F1-score for multi-label classification\n",
    "    f1_micro = f1_score(all_labels.numpy(), all_preds.numpy(), average='micro')  # F1-score for multi-label classification\n",
    "    conf_matrix = confusion_matrix(all_labels.numpy(), all_preds.numpy(), labels= [0, 1, 2, 3])\n",
    "    avg_loss = running_loss / num_val\n",
    "    \n",
    "    return avg_loss, accuracy, f1_micro, f1_macro, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22794934-d147-4deb-b1ab-631d0edb16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def load_checkpoint(model, optimizer=None, scheduler=None):\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pt'))        \n",
    "    # Extract epoch numbers and find latest\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "    \n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Load optimizer state if provided (for training)\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        # Move optimizer state to GPU if necessary\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(device)\n",
    "\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Get training metadata\n",
    "    epoch = checkpoint['epoch']\n",
    "    metrics = checkpoint['metrics']\n",
    "    \n",
    "    print(f\"Successfully loaded checkpoint from epoch {epoch}\")\n",
    "    print(\"Metrics at checkpoint:\", metrics)\n",
    "    \n",
    "    return model, optimizer, scheduler, epoch, metrics\n",
    "        \n",
    "\n",
    "# model, optimizer, scheduler, latest_epoch, metrics = load_checkpoint(model, optimizer, scheduler)\n",
    "latest_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b5b6e2-f317-4d97-a245-01fad9fd3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_ratio(epoch, decay_epochs=50000):\n",
    "    \"\"\"\n",
    "    Calculate partition ratio that decreases from 8/16 to 1/16 in steps\n",
    "    \"\"\"\n",
    "    # Calculate how many epochs before each step down\n",
    "    epochs_per_step = decay_epochs // 7  # 7 steps from 8/16 down to 1/16\n",
    "    \n",
    "    # Calculate current step based on epoch\n",
    "    step = min(epoch // epochs_per_step, 7)  # Max 7 steps down from 8\n",
    "    \n",
    "    # Map step to fraction\n",
    "    fraction = (8 - step) / 16\n",
    "    \n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eaa816-92f0-4251-9de2-6ed3748a2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4999/100000 [13:13<3:34:43,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5000/100000]\n",
      "Train Loss: 0.7249, Train Accuracy: 0.5000\n",
      "Train F1 (micro): 0.5000, Train F1 (macro): 0.1670\n",
      "Train Confusion Matrix:\n",
      "[[     0      0      0      0]\n",
      " [     7 159858    132      3]\n",
      " [     2 158436    130      6]\n",
      " [     0   1423      3      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5000/100000 [14:32<628:56:58, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.7211, Val Accuracy: 0.0080\n",
      "Val F1 (micro): 0.0080, Val F1 (macro): 0.0053\n",
      "Val Confusion Matrix:\n",
      "[[    0     0     0     0]\n",
      " [    0   256     0     0]\n",
      " [    0 31660     0     0]\n",
      " [    0    84     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7806/100000 [21:59<4:09:06,  6.17it/s]  "
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "train_preds = []\n",
    "train_labels = []\n",
    "current_lr = lr\n",
    "\n",
    "for epoch in tqdm(range(latest_epoch, latest_epoch + epochs)):\n",
    "    model.train()\n",
    "\n",
    "    current_partition = get_partition_ratio(epoch)\n",
    "\n",
    "    tensor_batch = CNN_prepare_batch(\n",
    "        virus_da.get_batch(),\n",
    "        non_virus_da.get_batch(),\n",
    "        max_seq_len,\n",
    "        partition=current_partition\n",
    "    )\n",
    "    tensor_batch.gpu(device)\n",
    "        \n",
    "    labels = tensor_batch.taxes[\"begining root\"]\n",
    "    outputs = model(\n",
    "        tensor_batch.seq_ids[\"batch_encoding\"],\n",
    "        tensor_batch.seq_ids[\"batch_global_features\"],\n",
    "        tensor_batch.seq_ids[\"batch_maks\"],\n",
    "    )\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    train_preds.append(preds.cpu())\n",
    "    train_labels.append(labels.cpu())\n",
    "    \n",
    "    if (epoch + 1) % val_epoch == 0:\n",
    "        # Calculate training metrics\n",
    "        all_train_preds = torch.cat(train_preds)\n",
    "        all_train_labels = torch.cat(train_labels)\n",
    "        \n",
    "        train_accuracy = accuracy_score(all_train_labels.numpy(), all_train_preds.numpy())\n",
    "        train_f1_micro = f1_score(all_train_labels.numpy(), all_train_preds.numpy(), average='micro')\n",
    "        train_f1_macro = f1_score(all_train_labels.numpy(), all_train_preds.numpy(), average='macro')\n",
    "        train_cm = confusion_matrix(all_train_labels.numpy(), all_train_preds.numpy(), labels=[0, 1, 2, 3])\n",
    "        train_loss = running_loss / val_epoch\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Train F1 (micro): {train_f1_micro:.4f}, Train F1 (macro): {train_f1_macro:.4f}\")\n",
    "        print(\"Train Confusion Matrix:\")\n",
    "        print(train_cm)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_cm = evaluate(model)\n",
    "        \n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Val F1 (micro): {val_f1_micro:.4f}, Val F1 (macro): {val_f1_macro:.4f}\")\n",
    "        print(\"Val Confusion Matrix:\")\n",
    "        print(val_cm)\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(epoch + loss.item())\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Create metrics dictionary for saving\n",
    "        metrics = {\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"train_f1_micro\": train_f1_micro,\n",
    "            \"train_f1_macro\": train_f1_macro,\n",
    "            \"train_confusion_matrix\": train_cm,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_f1_micro\": val_f1_micro,\n",
    "            \"val_f1_macro\": val_f1_macro,\n",
    "            \"val_confusion_matrix\": val_cm,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"current_portion\": current_partition,\n",
    "            \"lr\": current_lr\n",
    "        }\n",
    "\n",
    "        # Save periodic checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log(metrics)\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(epoch + loss.item())\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Reset training metrics\n",
    "        running_loss = 0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5266ec-7e66-460b-b433-3676bae2d7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
